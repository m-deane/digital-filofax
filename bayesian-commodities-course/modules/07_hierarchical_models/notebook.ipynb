{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 7: Hierarchical Models for Multiple Commodities\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this module, you will be able to:\n",
    "\n",
    "1. Understand hierarchical/multilevel model structures\n",
    "2. Distinguish between complete pooling, no pooling, and partial pooling\n",
    "3. Build hierarchical models with varying intercepts by commodity\n",
    "4. Implement varying slopes for commodity-specific relationships\n",
    "5. Model cross-commodity correlation structures\n",
    "6. Apply shrinkage to improve estimates for thinly-traded commodities\n",
    "7. Use hierarchical models for agricultural commodities with shared weather impacts\n",
    "\n",
    "## Why This Matters for Trading\n",
    "\n",
    "Commodities don't exist in isolation. They form interconnected complexes:\n",
    "\n",
    "**Energy Complex**:\n",
    "- WTI (West Texas Intermediate) crude oil\n",
    "- Brent crude oil\n",
    "- Natural gas\n",
    "- Share supply/demand drivers, but have distinct regional factors\n",
    "\n",
    "**Agricultural Complex**:\n",
    "- Corn, Wheat, Soybeans\n",
    "- Compete for farmland\n",
    "- Share weather risks (drought affects all)\n",
    "- Different demand patterns (food, feed, fuel)\n",
    "\n",
    "**Metals Complex**:\n",
    "- Gold, Silver, Copper\n",
    "- Economic growth affects all, but to varying degrees\n",
    "\n",
    "### Trading Advantages of Hierarchical Models\n",
    "\n",
    "1. **Information Borrowing**: Thinly-traded commodities (e.g., oats) borrow strength from liquid ones (e.g., corn)\n",
    "2. **Pairs Trading**: Identify when a commodity deviates from its complex (e.g., WTI-Brent spread)\n",
    "3. **Risk Management**: Model correlations for portfolio optimization\n",
    "4. **Shrinkage**: Regularize estimates to prevent overfitting\n",
    "5. **Cross-Sectional Analysis**: Which commodity in a complex is most/least sensitive to a driver?\n",
    "6. **Missing Data**: Forecast one commodity using information from others\n",
    "\n",
    "**Example**: If drought affects corn, wheat, and soybeans, but you only have recent corn data, the hierarchical model uses corn's drought response to update beliefs about wheat and soybean responses.\n",
    "\n",
    "This is **statistical arbitrage at the structural level**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(f\"PyMC version: {pm.__version__}\")\n",
    "print(f\"ArviZ version: {az.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction: Pooling Strategies\n",
    "\n",
    "### The Pooling Spectrum\n",
    "\n",
    "Suppose we have price data for 3 commodities and want to estimate each commodity's mean price.\n",
    "\n",
    "**Complete Pooling** (ignore differences):\n",
    "$$\n",
    "y_{ij} \\sim \\text{Normal}(\\mu, \\sigma)\n",
    "$$\n",
    "- One $\\mu$ for all commodities\n",
    "- Assumes all commodities are identical\n",
    "- **Problem**: Ignores commodity-specific factors\n",
    "\n",
    "**No Pooling** (independent estimates):\n",
    "$$\n",
    "y_{ij} \\sim \\text{Normal}(\\mu_j, \\sigma_j)\n",
    "$$\n",
    "- Separate $\\mu_j$ for each commodity $j$\n",
    "- No information sharing\n",
    "- **Problem**: Overfits with small samples, ignores commonalities\n",
    "\n",
    "**Partial Pooling** (hierarchical):\n",
    "$$\n",
    "\\begin{align}\n",
    "y_{ij} &\\sim \\text{Normal}(\\mu_j, \\sigma) \\\\\n",
    "\\mu_j &\\sim \\text{Normal}(\\mu_{\\text{global}}, \\tau)\n",
    "\\end{align}\n",
    "$$\n",
    "- Commodity-specific $\\mu_j$, but they share a common prior\n",
    "- **Shrinkage**: Estimates pulled toward group mean\n",
    "- **Best of both worlds**: Commodity differences + information borrowing\n",
    "\n",
    "### Trading Interpretation\n",
    "\n",
    "- **Complete pooling**: \"All energy commodities are the same\" (wrong)\n",
    "- **No pooling**: \"WTI and Brent are unrelated\" (misses correlation)\n",
    "- **Partial pooling**: \"They're different, but share common drivers\" (realistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data: 3 commodities with different means\n",
    "np.random.seed(42)\n",
    "\n",
    "# True parameters\n",
    "true_global_mean = 60.0\n",
    "true_tau = 8.0  # Between-commodity variation\n",
    "true_sigma = 5.0  # Within-commodity variation\n",
    "\n",
    "# 3 commodities: WTI, Brent, Natural Gas (converted to oil-equivalent)\n",
    "commodities = ['WTI', 'Brent', 'NatGas']\n",
    "n_commodities = len(commodities)\n",
    "n_obs_per_commodity = [50, 60, 30]  # Different sample sizes\n",
    "\n",
    "# Generate commodity-specific means\n",
    "np.random.seed(42)\n",
    "true_mu = np.array([58, 62, 55])  # WTI slightly below Brent, NatGas lower\n",
    "\n",
    "# Generate data\n",
    "data_list = []\n",
    "for j, (commodity, n_obs) in enumerate(zip(commodities, n_obs_per_commodity)):\n",
    "    prices = np.random.normal(true_mu[j], true_sigma, n_obs)\n",
    "    for price in prices:\n",
    "        data_list.append({'commodity': commodity, 'price': price})\n",
    "\n",
    "df_pooling = pd.DataFrame(data_list)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "positions = [1, 2, 3]\n",
    "for j, commodity in enumerate(commodities):\n",
    "    subset = df_pooling[df_pooling['commodity'] == commodity]['price']\n",
    "    ax.scatter([positions[j]] * len(subset), subset, alpha=0.5, s=50, label=commodity)\n",
    "    ax.plot([positions[j] - 0.3, positions[j] + 0.3], [true_mu[j], true_mu[j]], \n",
    "            'r-', linewidth=3, label='True Mean' if j == 0 else '')\n",
    "\n",
    "ax.axhline(true_global_mean, color='black', linestyle='--', linewidth=2, \n",
    "           label=f'Global Mean = {true_global_mean}')\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(commodities)\n",
    "ax.set_ylabel('Price ($/barrel equivalent)', fontsize=12)\n",
    "ax.set_title('Energy Commodity Prices: Different Means, Shared Drivers', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Data Summary:\")\n",
    "print(df_pooling.groupby('commodity')['price'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode commodities as integers for PyMC\n",
    "commodity_idx = pd.Categorical(df_pooling['commodity'], categories=commodities).codes\n",
    "y_pooling = df_pooling['price'].values\n",
    "\n",
    "# Model 1: Complete Pooling\n",
    "with pm.Model() as complete_pooling:\n",
    "    mu_global = pm.Normal('mu_global', mu=60, sigma=20)\n",
    "    sigma = pm.HalfNormal('sigma', sigma=10)\n",
    "    \n",
    "    y = pm.Normal('y', mu=mu_global, sigma=sigma, observed=y_pooling)\n",
    "    \n",
    "    trace_complete = pm.sample(2000, tune=1000, return_inferencedata=True, random_seed=42)\n",
    "\n",
    "# Model 2: No Pooling\n",
    "with pm.Model() as no_pooling:\n",
    "    mu = pm.Normal('mu', mu=60, sigma=20, shape=n_commodities)\n",
    "    sigma = pm.HalfNormal('sigma', sigma=10)\n",
    "    \n",
    "    y = pm.Normal('y', mu=mu[commodity_idx], sigma=sigma, observed=y_pooling)\n",
    "    \n",
    "    trace_no_pooling = pm.sample(2000, tune=1000, return_inferencedata=True, random_seed=42)\n",
    "\n",
    "# Model 3: Partial Pooling (Hierarchical)\n",
    "with pm.Model() as partial_pooling:\n",
    "    # Hyperpriors (group-level)\n",
    "    mu_global = pm.Normal('mu_global', mu=60, sigma=20)\n",
    "    tau = pm.HalfNormal('tau', sigma=10)  # Between-commodity std\n",
    "    \n",
    "    # Commodity-specific means\n",
    "    mu = pm.Normal('mu', mu=mu_global, sigma=tau, shape=n_commodities)\n",
    "    \n",
    "    # Observation model\n",
    "    sigma = pm.HalfNormal('sigma', sigma=10)\n",
    "    y = pm.Normal('y', mu=mu[commodity_idx], sigma=sigma, observed=y_pooling)\n",
    "    \n",
    "    trace_partial = pm.sample(2000, tune=1000, return_inferencedata=True, random_seed=42)\n",
    "\n",
    "print(\"\\n=== COMPLETE POOLING ===\")\n",
    "print(az.summary(trace_complete, var_names=['mu_global', 'sigma']))\n",
    "\n",
    "print(\"\\n=== NO POOLING ===\")\n",
    "print(az.summary(trace_no_pooling, var_names=['mu', 'sigma']))\n",
    "\n",
    "print(\"\\n=== PARTIAL POOLING ===\")\n",
    "print(az.summary(trace_partial, var_names=['mu_global', 'tau', 'mu', 'sigma']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare estimates\n",
    "complete_est = trace_complete.posterior['mu_global'].mean().item()\n",
    "no_pooling_est = trace_no_pooling.posterior['mu'].mean(dim=['chain', 'draw']).values\n",
    "partial_pooling_est = trace_partial.posterior['mu'].mean(dim=['chain', 'draw']).values\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(n_commodities)\n",
    "width = 0.2\n",
    "\n",
    "# True means\n",
    "ax.bar(x - 1.5*width, true_mu, width, label='True', alpha=0.8, color='black')\n",
    "\n",
    "# Complete pooling\n",
    "ax.bar(x - 0.5*width, [complete_est]*n_commodities, width, \n",
    "       label='Complete Pooling', alpha=0.7, color='red')\n",
    "\n",
    "# No pooling\n",
    "ax.bar(x + 0.5*width, no_pooling_est, width, \n",
    "       label='No Pooling', alpha=0.7, color='blue')\n",
    "\n",
    "# Partial pooling\n",
    "ax.bar(x + 1.5*width, partial_pooling_est, width, \n",
    "       label='Partial Pooling', alpha=0.7, color='green')\n",
    "\n",
    "ax.set_xlabel('Commodity', fontsize=12)\n",
    "ax.set_ylabel('Estimated Mean Price ($/barrel)', fontsize=12)\n",
    "ax.set_title('Pooling Strategies Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(commodities)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Quantify errors\n",
    "print(\"\\n=== ESTIMATION ERRORS (True - Estimated) ===\")\n",
    "print(f\"\\nComplete Pooling:\")\n",
    "for j, commodity in enumerate(commodities):\n",
    "    error = true_mu[j] - complete_est\n",
    "    print(f\"  {commodity}: {error:+.2f}\")\n",
    "print(f\"  RMSE: {np.sqrt(np.mean((true_mu - complete_est)**2)):.3f}\")\n",
    "\n",
    "print(f\"\\nNo Pooling:\")\n",
    "for j, commodity in enumerate(commodities):\n",
    "    error = true_mu[j] - no_pooling_est[j]\n",
    "    print(f\"  {commodity}: {error:+.2f}\")\n",
    "print(f\"  RMSE: {np.sqrt(np.mean((true_mu - no_pooling_est)**2)):.3f}\")\n",
    "\n",
    "print(f\"\\nPartial Pooling (Best):\")\n",
    "for j, commodity in enumerate(commodities):\n",
    "    error = true_mu[j] - partial_pooling_est[j]\n",
    "    print(f\"  {commodity}: {error:+.2f}\")\n",
    "print(f\"  RMSE: {np.sqrt(np.mean((true_mu - partial_pooling_est)**2)):.3f}\")\n",
    "\n",
    "print(\"\\n→ Partial pooling has lowest RMSE, especially for small-sample commodities (NatGas)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Shrinkage Effect\n",
    "\n",
    "### Theory\n",
    "\n",
    "Partial pooling **shrinks** commodity-specific estimates toward the group mean:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu}_j \\approx \\lambda \\bar{y}_j + (1 - \\lambda) \\mu_{\\text{global}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\lambda$: Shrinkage factor (depends on sample size and $\\tau/\\sigma$ ratio)\n",
    "- Small sample → low $\\lambda$ → strong shrinkage\n",
    "- Large sample → high $\\lambda$ → weak shrinkage\n",
    "\n",
    "### Trading Application\n",
    "\n",
    "- **Thinly-traded commodities**: Borrow strength from liquid ones\n",
    "- **New contracts**: Use existing commodity data to initialize forecasts\n",
    "- **Regularization**: Prevent overfitting on noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize shrinkage\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Sample means (raw data)\n",
    "sample_means = df_pooling.groupby('commodity')['price'].mean().values\n",
    "\n",
    "# Global mean\n",
    "global_mean = partial_pooling_est.mean()\n",
    "\n",
    "for j, commodity in enumerate(commodities):\n",
    "    # Arrow from sample mean to hierarchical estimate\n",
    "    ax.annotate('', xy=(j, partial_pooling_est[j]), xytext=(j, sample_means[j]),\n",
    "                arrowprops=dict(arrowstyle='->', lw=2, color='red', alpha=0.7))\n",
    "    \n",
    "    # Sample mean\n",
    "    ax.scatter(j, sample_means[j], s=200, color='blue', marker='o', \n",
    "               edgecolors='black', linewidths=2, zorder=5, label='Sample Mean' if j == 0 else '')\n",
    "    \n",
    "    # Hierarchical estimate\n",
    "    ax.scatter(j, partial_pooling_est[j], s=200, color='green', marker='s', \n",
    "               edgecolors='black', linewidths=2, zorder=5, label='Hierarchical Estimate' if j == 0 else '')\n",
    "    \n",
    "    # True mean\n",
    "    ax.scatter(j, true_mu[j], s=200, color='red', marker='^', \n",
    "               edgecolors='black', linewidths=2, zorder=5, label='True Mean' if j == 0 else '')\n",
    "    \n",
    "    # Sample size annotation\n",
    "    ax.text(j, sample_means[j] + 1.5, f'n={n_obs_per_commodity[j]}', \n",
    "            ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Global mean line\n",
    "ax.axhline(global_mean, color='purple', linestyle='--', linewidth=2, \n",
    "           label=f'Global Mean = {global_mean:.2f}', alpha=0.7)\n",
    "\n",
    "ax.set_xticks(range(n_commodities))\n",
    "ax.set_xticklabels(commodities)\n",
    "ax.set_ylabel('Price ($/barrel)', fontsize=12)\n",
    "ax.set_title('Shrinkage Effect: Sample Means → Hierarchical Estimates', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== SHRINKAGE ANALYSIS ===\")\n",
    "for j, commodity in enumerate(commodities):\n",
    "    shrinkage = sample_means[j] - partial_pooling_est[j]\n",
    "    print(f\"\\n{commodity} (n={n_obs_per_commodity[j]}):\")\n",
    "    print(f\"  Sample mean: {sample_means[j]:.2f}\")\n",
    "    print(f\"  Hierarchical estimate: {partial_pooling_est[j]:.2f}\")\n",
    "    print(f\"  Shrinkage: {shrinkage:+.2f} (toward global mean)\")\n",
    "    print(f\"  → {'STRONG' if abs(shrinkage) > 1 else 'WEAK'} shrinkage ({'small' if n_obs_per_commodity[j] < 40 else 'large'} sample)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Varying Intercepts and Slopes\n",
    "\n",
    "### Theory\n",
    "\n",
    "Extend hierarchical models to regression with commodity-specific intercepts AND slopes:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y_{ij} &\\sim \\text{Normal}(\\mu_{ij}, \\sigma) \\\\\n",
    "\\mu_{ij} &= \\alpha_j + \\beta_j x_i \\\\\n",
    "\\alpha_j &\\sim \\text{Normal}(\\mu_\\alpha, \\tau_\\alpha) \\\\\n",
    "\\beta_j &\\sim \\text{Normal}(\\mu_\\beta, \\tau_\\beta)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\alpha_j$: Commodity-specific intercept (base price)\n",
    "- $\\beta_j$: Commodity-specific slope (sensitivity to predictor)\n",
    "- $\\mu_\\alpha, \\tau_\\alpha$: Group-level intercept parameters\n",
    "- $\\mu_\\beta, \\tau_\\beta$: Group-level slope parameters\n",
    "\n",
    "### Trading Application\n",
    "\n",
    "**Question**: How much does each energy commodity respond to USD changes?\n",
    "\n",
    "- WTI might have $\\beta_{\\text{WTI}} = -1.2$ (highly sensitive)\n",
    "- Brent might have $\\beta_{\\text{Brent}} = -0.9$ (less sensitive, European market)\n",
    "- Natural gas might have $\\beta_{\\text{NatGas}} = -0.5$ (regional market, less USD-driven)\n",
    "\n",
    "Hierarchical model estimates these while preventing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with varying intercepts and slopes\n",
    "np.random.seed(42)\n",
    "n_per_commodity = 80\n",
    "\n",
    "# Predictor: USD index (standardized)\n",
    "usd_values = np.random.normal(0, 1, n_per_commodity * n_commodities)\n",
    "\n",
    "# True parameters\n",
    "true_alpha = np.array([60, 64, 56])  # Different base prices\n",
    "true_beta = np.array([-1.2, -0.9, -0.5])  # Different USD sensitivities\n",
    "true_sigma_y = 3.0\n",
    "\n",
    "# Generate prices\n",
    "data_varying = []\n",
    "for j, commodity in enumerate(commodities):\n",
    "    idx_start = j * n_per_commodity\n",
    "    idx_end = (j + 1) * n_per_commodity\n",
    "    \n",
    "    usd_subset = usd_values[idx_start:idx_end]\n",
    "    prices = true_alpha[j] + true_beta[j] * usd_subset + np.random.normal(0, true_sigma_y, n_per_commodity)\n",
    "    \n",
    "    for i, (usd, price) in enumerate(zip(usd_subset, prices)):\n",
    "        data_varying.append({\n",
    "            'commodity': commodity,\n",
    "            'usd': usd,\n",
    "            'price': price\n",
    "        })\n",
    "\n",
    "df_varying = pd.DataFrame(data_varying)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
    "\n",
    "colors = ['steelblue', 'darkorange', 'green']\n",
    "for j, commodity in enumerate(commodities):\n",
    "    subset = df_varying[df_varying['commodity'] == commodity]\n",
    "    \n",
    "    axes[j].scatter(subset['usd'], subset['price'], alpha=0.5, s=30, color=colors[j])\n",
    "    \n",
    "    # True regression line\n",
    "    usd_range = np.linspace(-3, 3, 100)\n",
    "    axes[j].plot(usd_range, true_alpha[j] + true_beta[j] * usd_range, \n",
    "                 'r--', linewidth=2, label=f'True: α={true_alpha[j]:.1f}, β={true_beta[j]:.1f}')\n",
    "    \n",
    "    axes[j].set_xlabel('USD Index (standardized)', fontsize=11)\n",
    "    if j == 0:\n",
    "        axes[j].set_ylabel('Price ($/barrel)', fontsize=11)\n",
    "    axes[j].set_title(f'{commodity}', fontsize=12, fontweight='bold')\n",
    "    axes[j].legend(loc='upper right')\n",
    "    axes[j].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNote: Different slopes show varying USD sensitivity across commodities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build hierarchical model with varying intercepts and slopes\n",
    "commodity_idx_varying = pd.Categorical(df_varying['commodity'], categories=commodities).codes\n",
    "usd_varying = df_varying['usd'].values\n",
    "y_varying = df_varying['price'].values\n",
    "\n",
    "with pm.Model() as varying_model:\n",
    "    # Hyperpriors for intercepts\n",
    "    mu_alpha = pm.Normal('mu_alpha', mu=60, sigma=10)\n",
    "    tau_alpha = pm.HalfNormal('tau_alpha', sigma=10)\n",
    "    \n",
    "    # Hyperpriors for slopes\n",
    "    mu_beta = pm.Normal('mu_beta', mu=-1, sigma=2)\n",
    "    tau_beta = pm.HalfNormal('tau_beta', sigma=1)\n",
    "    \n",
    "    # Commodity-specific intercepts and slopes\n",
    "    alpha = pm.Normal('alpha', mu=mu_alpha, sigma=tau_alpha, shape=n_commodities)\n",
    "    beta = pm.Normal('beta', mu=mu_beta, sigma=tau_beta, shape=n_commodities)\n",
    "    \n",
    "    # Observation noise\n",
    "    sigma_y = pm.HalfNormal('sigma_y', sigma=10)\n",
    "    \n",
    "    # Regression\n",
    "    mu = alpha[commodity_idx_varying] + beta[commodity_idx_varying] * usd_varying\n",
    "    \n",
    "    # Likelihood\n",
    "    y = pm.Normal('y', mu=mu, sigma=sigma_y, observed=y_varying)\n",
    "    \n",
    "    # Sample\n",
    "    trace_varying = pm.sample(2000, tune=1000, return_inferencedata=True, random_seed=42)\n",
    "\n",
    "print(\"\\nPosterior Summary:\")\n",
    "print(az.summary(trace_varying, var_names=['mu_alpha', 'tau_alpha', 'mu_beta', 'tau_beta', \n",
    "                                            'alpha', 'beta', 'sigma_y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize estimates\n",
    "alpha_est = trace_varying.posterior['alpha'].mean(dim=['chain', 'draw']).values\n",
    "beta_est = trace_varying.posterior['beta'].mean(dim=['chain', 'draw']).values\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
    "\n",
    "for j, commodity in enumerate(commodities):\n",
    "    subset = df_varying[df_varying['commodity'] == commodity]\n",
    "    \n",
    "    axes[j].scatter(subset['usd'], subset['price'], alpha=0.4, s=30, color=colors[j], label='Data')\n",
    "    \n",
    "    # True line\n",
    "    usd_range = np.linspace(-3, 3, 100)\n",
    "    axes[j].plot(usd_range, true_alpha[j] + true_beta[j] * usd_range, \n",
    "                 'r--', linewidth=2, alpha=0.7, label=f'True: α={true_alpha[j]:.1f}, β={true_beta[j]:.2f}')\n",
    "    \n",
    "    # Estimated line\n",
    "    axes[j].plot(usd_range, alpha_est[j] + beta_est[j] * usd_range, \n",
    "                 'b-', linewidth=2.5, label=f'Est: α={alpha_est[j]:.1f}, β={beta_est[j]:.2f}')\n",
    "    \n",
    "    axes[j].set_xlabel('USD Index (standardized)', fontsize=11)\n",
    "    if j == 0:\n",
    "        axes[j].set_ylabel('Price ($/barrel)', fontsize=11)\n",
    "    axes[j].set_title(f'{commodity}', fontsize=12, fontweight='bold')\n",
    "    axes[j].legend(loc='upper right', fontsize=9)\n",
    "    axes[j].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Trading analysis\n",
    "print(\"\\n=== USD SENSITIVITY ANALYSIS ===\")\n",
    "for j, commodity in enumerate(commodities):\n",
    "    beta_samples = trace_varying.posterior['beta'].values[:, :, j].flatten()\n",
    "    beta_mean = beta_samples.mean()\n",
    "    beta_ci = np.percentile(beta_samples, [2.5, 97.5])\n",
    "    \n",
    "    print(f\"\\n{commodity}:\")\n",
    "    print(f\"  β (USD): {beta_mean:.3f} (95% CI: [{beta_ci[0]:.3f}, {beta_ci[1]:.3f}])\")\n",
    "    print(f\"  True β: {true_beta[j]:.3f}\")\n",
    "    \n",
    "    if abs(beta_mean) > 1.0:\n",
    "        print(f\"  → HIGH SENSITIVITY: 1% USD move → {abs(beta_mean):.2f}% price move\")\n",
    "    elif abs(beta_mean) > 0.7:\n",
    "        print(f\"  → MODERATE SENSITIVITY: 1% USD move → {abs(beta_mean):.2f}% price move\")\n",
    "    else:\n",
    "        print(f\"  → LOW SENSITIVITY: USD less important driver\")\n",
    "\n",
    "# Group-level parameters\n",
    "mu_beta_samples = trace_varying.posterior['mu_beta'].values.flatten()\n",
    "print(f\"\\n\\nGroup-level β (average across commodities): {mu_beta_samples.mean():.3f}\")\n",
    "print(f\"Between-commodity variation (τ_β): {trace_varying.posterior['tau_beta'].values.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-Commodity Correlation Structure\n",
    "\n",
    "### Theory\n",
    "\n",
    "So far, we've assumed commodities are independent conditional on group parameters. But energy commodities are correlated due to shared shocks.\n",
    "\n",
    "**Multivariate hierarchical model**:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \\alpha_1 \\\\ \\alpha_2 \\\\ \\alpha_3 \\end{bmatrix} \\sim \\text{MVNormal}(\\boldsymbol{\\mu}_\\alpha, \\boldsymbol{\\Sigma}_\\alpha)\n",
    "$$\n",
    "\n",
    "Where $\\boldsymbol{\\Sigma}_\\alpha$ is a covariance matrix capturing correlations between commodity intercepts.\n",
    "\n",
    "### Trading Application\n",
    "\n",
    "- **Pairs trading**: If WTI and Brent have correlation 0.95, large deviations signal arbitrage\n",
    "- **Portfolio construction**: Use correlation matrix for optimal hedging\n",
    "- **Risk management**: Diversification benefits depend on cross-commodity correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate correlated commodity returns\n",
    "np.random.seed(42)\n",
    "T_corr = 200\n",
    "\n",
    "# True correlation matrix\n",
    "# WTI-Brent: 0.95 (highly correlated)\n",
    "# WTI-NatGas: 0.60\n",
    "# Brent-NatGas: 0.55\n",
    "true_corr = np.array([\n",
    "    [1.00, 0.95, 0.60],\n",
    "    [0.95, 1.00, 0.55],\n",
    "    [0.60, 0.55, 1.00]\n",
    "])\n",
    "\n",
    "# Standard deviations\n",
    "true_stds = np.array([2.0, 2.1, 3.5])  # NatGas more volatile\n",
    "\n",
    "# Covariance matrix\n",
    "true_cov = np.outer(true_stds, true_stds) * true_corr\n",
    "\n",
    "# Generate multivariate normal returns\n",
    "mean_returns = np.array([0.05, 0.06, 0.03])  # Daily returns (%)\n",
    "returns = np.random.multivariate_normal(mean_returns, true_cov, T_corr)\n",
    "\n",
    "# Convert to prices\n",
    "prices_corr = np.zeros((T_corr, n_commodities))\n",
    "prices_corr[0] = [60, 64, 56]\n",
    "for t in range(1, T_corr):\n",
    "    prices_corr[t] = prices_corr[t-1] * (1 + returns[t] / 100)\n",
    "\n",
    "df_corr = pd.DataFrame(prices_corr, columns=commodities)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Price series\n",
    "for j, commodity in enumerate(commodities):\n",
    "    axes[0, 0].plot(df_corr[commodity], label=commodity, linewidth=1.5, color=colors[j])\n",
    "axes[0, 0].set_xlabel('Time (days)', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Price ($/barrel)', fontsize=11)\n",
    "axes[0, 0].set_title('Correlated Commodity Prices', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter: WTI vs Brent\n",
    "axes[0, 1].scatter(df_corr['WTI'], df_corr['Brent'], alpha=0.5, s=20)\n",
    "axes[0, 1].set_xlabel('WTI Price', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Brent Price', fontsize=11)\n",
    "axes[0, 1].set_title(f'WTI vs Brent (ρ = {true_corr[0, 1]:.2f})', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter: WTI vs NatGas\n",
    "axes[1, 0].scatter(df_corr['WTI'], df_corr['NatGas'], alpha=0.5, s=20, color='green')\n",
    "axes[1, 0].set_xlabel('WTI Price', fontsize=11)\n",
    "axes[1, 0].set_ylabel('NatGas Price', fontsize=11)\n",
    "axes[1, 0].set_title(f'WTI vs NatGas (ρ = {true_corr[0, 2]:.2f})', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Correlation heatmap\n",
    "im = axes[1, 1].imshow(true_corr, cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "axes[1, 1].set_xticks(range(n_commodities))\n",
    "axes[1, 1].set_yticks(range(n_commodities))\n",
    "axes[1, 1].set_xticklabels(commodities)\n",
    "axes[1, 1].set_yticklabels(commodities)\n",
    "axes[1, 1].set_title('True Correlation Matrix', fontsize=12, fontweight='bold')\n",
    "for i in range(n_commodities):\n",
    "    for j in range(n_commodities):\n",
    "        axes[1, 1].text(j, i, f'{true_corr[i, j]:.2f}', ha='center', va='center', fontsize=12)\n",
    "plt.colorbar(im, ax=axes[1, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Sample correlation matrix:\")\n",
    "print(df_corr.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build hierarchical model with correlated effects\n",
    "# For simplicity, we'll estimate correlations from returns rather than full multivariate model\n",
    "\n",
    "# Calculate returns\n",
    "returns_df = df_corr.pct_change().dropna() * 100  # Percentage returns\n",
    "\n",
    "# Stack data for PyMC\n",
    "returns_stacked = returns_df.values.flatten()\n",
    "commodity_idx_corr = np.repeat(np.arange(n_commodities), len(returns_df))\n",
    "\n",
    "with pm.Model() as corr_model:\n",
    "    # Mean returns by commodity\n",
    "    mu_return = pm.Normal('mu_return', mu=0, sigma=1, shape=n_commodities)\n",
    "    \n",
    "    # Cholesky decomposition for covariance\n",
    "    sd_dist = pm.HalfNormal.dist(sigma=5, shape=n_commodities)\n",
    "    chol, corr, stds = pm.LKJCholeskyCov('chol', n=n_commodities, eta=2.0, sd_dist=sd_dist)\n",
    "    \n",
    "    # Observation model (simplified: independent given parameters)\n",
    "    # In practice, you'd use multivariate normal\n",
    "    sigma_obs = pm.Deterministic('sigma_obs', stds)\n",
    "    \n",
    "    # For computational efficiency, use independent normal per commodity\n",
    "    # (Full multivariate model would be pm.MvNormal)\n",
    "    y = pm.Normal('y', mu=mu_return[commodity_idx_corr], \n",
    "                  sigma=sigma_obs[commodity_idx_corr], \n",
    "                  observed=returns_stacked)\n",
    "    \n",
    "    # Sample\n",
    "    trace_corr = pm.sample(2000, tune=1000, return_inferencedata=True, \n",
    "                           target_accept=0.95, random_seed=42, chains=2)\n",
    "\n",
    "print(\"\\nPosterior Summary:\")\n",
    "print(az.summary(trace_corr, var_names=['mu_return', 'sigma_obs', 'corr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract estimated correlation matrix\n",
    "corr_est = trace_corr.posterior['corr'].mean(dim=['chain', 'draw']).values\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# True correlations\n",
    "im1 = axes[0].imshow(true_corr, cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "axes[0].set_xticks(range(n_commodities))\n",
    "axes[0].set_yticks(range(n_commodities))\n",
    "axes[0].set_xticklabels(commodities)\n",
    "axes[0].set_yticklabels(commodities)\n",
    "axes[0].set_title('True Correlations', fontsize=12, fontweight='bold')\n",
    "for i in range(n_commodities):\n",
    "    for j in range(n_commodities):\n",
    "        axes[0].text(j, i, f'{true_corr[i, j]:.2f}', ha='center', va='center', fontsize=11)\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Estimated correlations\n",
    "im2 = axes[1].imshow(corr_est, cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "axes[1].set_xticks(range(n_commodities))\n",
    "axes[1].set_yticks(range(n_commodities))\n",
    "axes[1].set_xticklabels(commodities)\n",
    "axes[1].set_yticklabels(commodities)\n",
    "axes[1].set_title('Estimated Correlations (Bayesian)', fontsize=12, fontweight='bold')\n",
    "for i in range(n_commodities):\n",
    "    for j in range(n_commodities):\n",
    "        axes[1].text(j, i, f'{corr_est[i, j]:.2f}', ha='center', va='center', fontsize=11)\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== TRADING INSIGHTS ===\")\n",
    "print(f\"\\nWTI-Brent Correlation: {corr_est[0, 1]:.3f}\")\n",
    "if corr_est[0, 1] > 0.9:\n",
    "    print(\"  → HIGHLY CORRELATED: WTI-Brent spread trades require small deviations\")\n",
    "    print(\"     Strategy: Mean-reversion on spread, tight stop-loss\")\n",
    "\n",
    "print(f\"\\nWTI-NatGas Correlation: {corr_est[0, 2]:.3f}\")\n",
    "print(f\"Brent-NatGas Correlation: {corr_est[1, 2]:.3f}\")\n",
    "if corr_est[0, 2] < 0.7:\n",
    "    print(\"  → MODERATE CORRELATION: NatGas provides diversification\")\n",
    "    print(\"     Strategy: Use NatGas to hedge crude oil exposure (imperfect hedge)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Practical Application: Agricultural Commodities with Shared Weather\n",
    "\n",
    "### Trading Context\n",
    "\n",
    "Corn, Wheat, and Soybeans:\n",
    "- **Compete for farmland**: Farmers allocate acres based on expected profits\n",
    "- **Share weather risks**: Drought in the Midwest affects all three\n",
    "- **Different markets**: Corn (feed, ethanol), Wheat (food), Soybeans (feed, oil)\n",
    "\n",
    "We'll model:\n",
    "- Varying intercepts (different base prices)\n",
    "- Varying slopes for rainfall impact\n",
    "- Shared seasonality (harvest depression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate agricultural commodity data\n",
    "np.random.seed(42)\n",
    "T_ag = 120  # 10 years of monthly data\n",
    "\n",
    "ag_commodities = ['Corn', 'Wheat', 'Soybeans']\n",
    "n_ag = len(ag_commodities)\n",
    "\n",
    "# Rainfall index (standardized)\n",
    "rainfall = np.random.normal(0, 1, T_ag)\n",
    "\n",
    "# Month of year (for seasonality)\n",
    "month = np.arange(T_ag) % 12\n",
    "\n",
    "# Harvest months: September-October (months 8-9)\n",
    "harvest_effect = np.where((month == 8) | (month == 9), -20, 0)\n",
    "\n",
    "# True parameters\n",
    "true_alpha_ag = np.array([400, 600, 1100])  # Base prices (cents/bushel)\n",
    "true_beta_rain = np.array([-15, -12, -18])  # Rainfall effect (drought → higher prices)\n",
    "\n",
    "# Generate prices\n",
    "prices_ag = np.zeros((T_ag, n_ag))\n",
    "for j in range(n_ag):\n",
    "    trend = true_alpha_ag[j] + 0.5 * np.arange(T_ag)  # Slight uptrend\n",
    "    prices_ag[:, j] = (trend + \n",
    "                       true_beta_rain[j] * rainfall + \n",
    "                       harvest_effect + \n",
    "                       np.random.normal(0, 25, T_ag))\n",
    "\n",
    "df_ag = pd.DataFrame(prices_ag, columns=ag_commodities)\n",
    "df_ag['rainfall'] = rainfall\n",
    "df_ag['month'] = month\n",
    "df_ag['time'] = np.arange(T_ag)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Prices\n",
    "for commodity in ag_commodities:\n",
    "    axes[0].plot(df_ag['time'], df_ag[commodity], label=commodity, linewidth=1.5)\n",
    "axes[0].set_ylabel('Price (cents/bushel)', fontsize=11)\n",
    "axes[0].set_title('Agricultural Commodity Prices', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Rainfall\n",
    "axes[1].bar(df_ag['time'], df_ag['rainfall'], alpha=0.6, color='blue')\n",
    "axes[1].axhline(0, color='black', linestyle='--')\n",
    "axes[1].set_ylabel('Rainfall Index', fontsize=11)\n",
    "axes[1].set_title('Rainfall (negative = drought)', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Harvest seasonality\n",
    "axes[2].bar(df_ag['time'], harvest_effect, alpha=0.6, color='orange')\n",
    "axes[2].set_xlabel('Time (months)', fontsize=11)\n",
    "axes[2].set_ylabel('Harvest Effect (cents)', fontsize=11)\n",
    "axes[2].set_title('Seasonal Harvest Pressure', fontsize=12, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "# Stack prices\n",
    "prices_stacked = df_ag[ag_commodities].values.flatten()\n",
    "rainfall_stacked = np.tile(df_ag['rainfall'].values, n_ag)\n",
    "month_stacked = np.tile(df_ag['month'].values, n_ag)\n",
    "commodity_idx_ag = np.repeat(np.arange(n_ag), T_ag)\n",
    "\n",
    "# Build hierarchical model\n",
    "with pm.Model() as ag_model:\n",
    "    # Hyperpriors for base prices\n",
    "    mu_alpha = pm.Normal('mu_alpha', mu=700, sigma=500)\n",
    "    tau_alpha = pm.HalfNormal('tau_alpha', sigma=500)\n",
    "    \n",
    "    # Hyperpriors for rainfall sensitivity\n",
    "    mu_beta_rain = pm.Normal('mu_beta_rain', mu=-15, sigma=10)\n",
    "    tau_beta_rain = pm.HalfNormal('tau_beta_rain', sigma=10)\n",
    "    \n",
    "    # Commodity-specific parameters\n",
    "    alpha = pm.Normal('alpha', mu=mu_alpha, sigma=tau_alpha, shape=n_ag)\n",
    "    beta_rain = pm.Normal('beta_rain', mu=mu_beta_rain, sigma=tau_beta_rain, shape=n_ag)\n",
    "    \n",
    "    # Shared harvest seasonality (2 months)\n",
    "    harvest_sep = pm.Normal('harvest_sep', mu=-20, sigma=10)  # September\n",
    "    harvest_oct = pm.Normal('harvest_oct', mu=-20, sigma=10)  # October\n",
    "    \n",
    "    # Map harvest effects to months\n",
    "    harvest_effects = pm.math.switch(\n",
    "        pm.math.eq(month_stacked, 8), harvest_sep,\n",
    "        pm.math.switch(pm.math.eq(month_stacked, 9), harvest_oct, 0)\n",
    "    )\n",
    "    \n",
    "    # Observation noise\n",
    "    sigma_y = pm.HalfNormal('sigma_y', sigma=50)\n",
    "    \n",
    "    # Combined mean\n",
    "    mu = (alpha[commodity_idx_ag] + \n",
    "          beta_rain[commodity_idx_ag] * rainfall_stacked + \n",
    "          harvest_effects)\n",
    "    \n",
    "    # Likelihood\n",
    "    y = pm.Normal('y', mu=mu, sigma=sigma_y, observed=prices_stacked)\n",
    "    \n",
    "    # Sample\n",
    "    trace_ag = pm.sample(2000, tune=1000, return_inferencedata=True, \n",
    "                         target_accept=0.95, random_seed=42, chains=2)\n",
    "\n",
    "print(\"\\nPosterior Summary:\")\n",
    "print(az.summary(trace_ag, var_names=['mu_alpha', 'tau_alpha', 'mu_beta_rain', 'tau_beta_rain',\n",
    "                                       'alpha', 'beta_rain', 'harvest_sep', 'harvest_oct', 'sigma_y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract estimates\n",
    "alpha_ag_est = trace_ag.posterior['alpha'].mean(dim=['chain', 'draw']).values\n",
    "beta_rain_est = trace_ag.posterior['beta_rain'].mean(dim=['chain', 'draw']).values\n",
    "harvest_sep_est = trace_ag.posterior['harvest_sep'].mean().item()\n",
    "harvest_oct_est = trace_ag.posterior['harvest_oct'].mean().item()\n",
    "\n",
    "# Comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Base prices\n",
    "x_pos = np.arange(n_ag)\n",
    "axes[0].bar(x_pos - 0.2, true_alpha_ag, width=0.4, label='True', alpha=0.7, color='green')\n",
    "axes[0].bar(x_pos + 0.2, alpha_ag_est, width=0.4, label='Estimated', alpha=0.7, color='steelblue')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(ag_commodities)\n",
    "axes[0].set_ylabel('Base Price (cents/bushel)', fontsize=11)\n",
    "axes[0].set_title('Commodity Base Prices (α)', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Rainfall sensitivity\n",
    "axes[1].bar(x_pos - 0.2, true_beta_rain, width=0.4, label='True', alpha=0.7, color='green')\n",
    "axes[1].bar(x_pos + 0.2, beta_rain_est, width=0.4, label='Estimated', alpha=0.7, color='steelblue')\n",
    "axes[1].axhline(0, color='black', linestyle='--')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(ag_commodities)\n",
    "axes[1].set_ylabel('Rainfall Sensitivity (β)', fontsize=11)\n",
    "axes[1].set_title('Drought Impact (negative rainfall → higher prices)', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Trading dashboard\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"AGRICULTURAL COMMODITY TRADING DASHBOARD\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for j, commodity in enumerate(ag_commodities):\n",
    "    beta_samples = trace_ag.posterior['beta_rain'].values[:, :, j].flatten()\n",
    "    prob_drought_bullish = np.mean(beta_samples < 0)\n",
    "    \n",
    "    print(f\"\\n{commodity}:\")\n",
    "    print(f\"  Base price: {alpha_ag_est[j]:.1f} cents/bushel\")\n",
    "    print(f\"  Rainfall β: {beta_rain_est[j]:.2f} (95% CI: [{np.percentile(beta_samples, 2.5):.2f}, {np.percentile(beta_samples, 97.5):.2f}])\")\n",
    "    print(f\"  Prob(drought increases prices): {prob_drought_bullish:.2%}\")\n",
    "    \n",
    "    if abs(beta_rain_est[j]) > 15:\n",
    "        print(f\"  → HIGH DROUGHT SENSITIVITY: Weather derivatives highly valuable\")\n",
    "    else:\n",
    "        print(f\"  → MODERATE DROUGHT SENSITIVITY\")\n",
    "\n",
    "print(f\"\\n\\nShared Harvest Effects:\")\n",
    "print(f\"  September: {harvest_sep_est:.1f} cents (harvest pressure)\")\n",
    "print(f\"  October: {harvest_oct_est:.1f} cents (harvest pressure)\")\n",
    "print(f\"\\n  → Strategy: Short ag futures ahead of harvest, cover in November\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Check Quiz\n",
    "\n",
    "### Question 1\n",
    "What is the main advantage of partial pooling over no pooling?\n",
    "\n",
    "A) Faster computation  \n",
    "B) Borrows strength across groups, reducing overfitting  \n",
    "C) Assumes all groups are identical  \n",
    "D) Eliminates the need for priors  \n",
    "\n",
    "**Answer: B** - Partial pooling shares information between related groups while allowing group-specific parameters, reducing overfitting especially with small samples.\n",
    "\n",
    "---\n",
    "\n",
    "### Question 2\n",
    "When does shrinkage have the strongest effect in hierarchical models?\n",
    "\n",
    "A) Large sample sizes  \n",
    "B) Small sample sizes  \n",
    "C) Equal sample sizes  \n",
    "D) Shrinkage is always the same  \n",
    "\n",
    "**Answer: B** - Groups with small samples are shrunk more toward the group mean, borrowing strength from better-estimated groups.\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3\n",
    "What does a varying slopes model estimate?\n",
    "\n",
    "A) Only intercepts differ by group  \n",
    "B) Only slopes differ by group  \n",
    "C) Both intercepts and slopes can differ by group  \n",
    "D) All parameters are identical  \n",
    "\n",
    "**Answer: C** - Varying slopes models allow both intercepts (base levels) and slopes (sensitivities) to differ across groups.\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4\n",
    "Why is modeling cross-commodity correlations important for trading?\n",
    "\n",
    "A) It makes models more complex  \n",
    "B) It's required by regulators  \n",
    "C) For portfolio construction, hedging, and pairs trading  \n",
    "D) It eliminates all risk  \n",
    "\n",
    "**Answer: C** - Correlations determine diversification benefits, hedging effectiveness, and spread trading opportunities.\n",
    "\n",
    "---\n",
    "\n",
    "### Question 5\n",
    "In the agricultural model, what does a negative β (rainfall) coefficient indicate?\n",
    "\n",
    "A) More rainfall increases prices  \n",
    "B) Drought (low rainfall) increases prices  \n",
    "C) Rainfall has no effect  \n",
    "D) The model is wrong  \n",
    "\n",
    "**Answer: B** - Negative coefficient means low rainfall (drought) is associated with higher prices due to reduced yields.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Energy Spread Trading\n",
    "Using the WTI-Brent correlation model:\n",
    "1. Define the spread as: Brent - WTI\n",
    "2. Model the spread as a mean-reverting process\n",
    "3. Calculate the equilibrium spread (mean)\n",
    "4. Design a pairs trading rule: long spread when 2σ below mean, short when 2σ above\n",
    "5. Backtest on the generated data\n",
    "\n",
    "### Exercise 2: Portfolio Optimization\n",
    "Given estimated correlations for energy commodities:\n",
    "1. Assume equal expected returns\n",
    "2. Use correlation matrix to compute minimum variance portfolio weights\n",
    "3. Compare diversified portfolio volatility to single-commodity volatility\n",
    "4. Calculate diversification benefit\n",
    "\n",
    "### Exercise 3: Drought Scenario Analysis\n",
    "For agricultural commodities:\n",
    "1. Simulate a severe drought: rainfall = -2 (2 std below normal) for 6 months\n",
    "2. Forecast price impact for each commodity\n",
    "3. Which commodity benefits most from drought?\n",
    "4. Calculate portfolio P&L if long all three commodities equally\n",
    "\n",
    "### Exercise 4: Hierarchical Volatility Model\n",
    "Build a model where volatility (σ) varies by commodity:\n",
    "$$\n",
    "\\sigma_j \\sim \\text{HalfNormal}(\\mu_\\sigma, \\tau_\\sigma)\n",
    "$$\n",
    "1. Estimate commodity-specific volatilities\n",
    "2. Rank commodities by volatility\n",
    "3. Design position sizing rule: allocate inversely to volatility\n",
    "4. Compare to equal-weighted portfolio\n",
    "\n",
    "### Exercise 5: Forecasting with Missing Data\n",
    "Simulate missing data scenario:\n",
    "1. Remove last 30 days of Soybeans prices\n",
    "2. Re-estimate hierarchical model using only Corn and Wheat\n",
    "3. Use group-level parameters to forecast Soybeans\n",
    "4. Compare forecast accuracy to model fit on complete data\n",
    "5. Quantify information borrowing benefit\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this module, you learned:\n",
    "\n",
    "1. **Pooling Strategies**: Complete, none, and partial pooling for multi-group data\n",
    "2. **Shrinkage**: How hierarchical models regularize estimates toward group means\n",
    "3. **Varying Intercepts & Slopes**: Commodity-specific parameters with shared priors\n",
    "4. **Cross-Commodity Correlations**: Modeling dependencies for portfolio decisions\n",
    "5. **Agricultural Application**: Weather impacts across related commodities\n",
    "\n",
    "### Key Takeaways for Trading\n",
    "\n",
    "- **Information Borrowing**: Improve estimates for thinly-traded commodities\n",
    "- **Regularization**: Prevent overfitting via shrinkage to group mean\n",
    "- **Pairs Trading**: Identify relative mispricings within commodity complexes\n",
    "- **Risk Management**: Model correlations for optimal portfolio construction\n",
    "- **Cross-Sectional Analysis**: Which commodity is most/least sensitive to shared drivers?\n",
    "- **Scenario Analysis**: Forecast impact of shocks (drought, OPEC cuts) across complex\n",
    "\n",
    "Hierarchical models are essential when:\n",
    "- You have **multiple related assets** (energy complex, grains, metals)\n",
    "- **Sample sizes vary** (some commodities thinly traded)\n",
    "- You want to **share information** without assuming homogeneity\n",
    "- **Correlations matter** for hedging and diversification\n",
    "\n",
    "This framework scales from 3 commodities (as shown) to dozens, enabling systematic cross-sectional strategies.\n",
    "\n",
    "---\n",
    "\n",
    "## Course Summary & Next Steps\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "Across Modules 1-7, you've built a complete Bayesian toolkit for commodity trading:\n",
    "\n",
    "1. **Foundations**: Bayesian inference, prior/posterior, MCMC\n",
    "2. **Prior Selection**: Informative, weakly informative, and regularizing priors\n",
    "3. **MCMC Inference**: Sampling, convergence diagnostics, trace analysis\n",
    "4. **Time Series**: Autocorrelation, stationarity, seasonality\n",
    "5. **Bayesian Linear Regression**: Uncertainty quantification, robust models\n",
    "6. **BSTS**: Trend, seasonality, dynamic regression, state-space models\n",
    "7. **Hierarchical Models**: Multi-commodity analysis, shrinkage, correlations\n",
    "\n",
    "### Remaining Modules (8-10)\n",
    "\n",
    "- **Module 8: Gaussian Processes** - Non-parametric flexible curves for price discovery\n",
    "- **Module 9: Volatility Modeling** - GARCH, stochastic volatility, VIX forecasting\n",
    "- **Module 10: Trading Strategies** - Complete systematic strategies with backtesting\n",
    "\n",
    "### Practice Recommendations\n",
    "\n",
    "1. **Real data**: Apply to actual commodity prices (FRED, Quandl, Yahoo Finance)\n",
    "2. **Daily practice**: Build one small model per day\n",
    "3. **Paper trading**: Test forecasts in real-time before risking capital\n",
    "4. **Community**: Share models, get feedback, iterate\n",
    "\n",
    "### Resources\n",
    "\n",
    "- PyMC Documentation: https://www.pymc.io/\n",
    "- ArviZ Gallery: https://arviz-devs.github.io/arviz/\n",
    "- Statistical Rethinking (McElreath): Excellent Bayesian textbook\n",
    "- BDA3 (Gelman et al.): Bayesian Data Analysis reference\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations on completing Module 7! You now have the statistical tools to build sophisticated multi-commodity trading models. Keep practicing, and see you in Module 8!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
