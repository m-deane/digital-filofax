{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Prior Selection and Market Knowledge Encoding\n",
    "\n",
    "**Course**: Bayesian Regression and Time Series Forecasting for Commodities Trading\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this module, you will be able to:\n",
    "\n",
    "1. **Translate** domain expertise into mathematically rigorous prior distributions\n",
    "2. **Select** appropriate conjugate priors for computational efficiency\n",
    "3. **Elicit** priors from historical commodity volatility and seasonality patterns\n",
    "4. **Distinguish** between weakly informative, informative, and strongly informative priors\n",
    "5. **Validate** prior distributions using prior predictive checks\n",
    "6. **Assess** prior sensitivity to ensure robust conclusions\n",
    "7. **Implement** prior selection for real commodity forecasting problems\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Matters for Trading\n",
    "\n",
    "Prior selection is where **Bayesian methods transform from mathematical theory into trading edge**. In commodity markets:\n",
    "\n",
    "- **Seasonality is real**: Corn prices peak before harvest, natural gas spikes in winter\n",
    "- **Mean reversion exists**: Crude oil historically reverts to marginal production cost ($40-80/barrel)\n",
    "- **Volatility clusters**: High volatility periods follow market shocks (2008, 2020)\n",
    "- **Regimes shift**: OPEC decisions, climate events, and policy changes alter market dynamics\n",
    "\n",
    "**Without priors**, your model treats a 300% oil price spike as equally likely as a 2% move. With intelligent priors:\n",
    "- You **regularize** estimates when data is noisy\n",
    "- You **encode** decades of market knowledge into models\n",
    "- You **prevent** overfitting to recent anomalies\n",
    "- You **quantify** how strongly beliefs should influence decisions\n",
    "\n",
    "**Bad priors** can bias your models. **Good priors** are the difference between a model that crashes in live trading and one that systematically makes money.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Prior Spectrum: From Ignorance to Certainty\n",
    "\n",
    "Priors exist on a continuum from complete ignorance to near-certainty:\n",
    "\n",
    "| Prior Type | When to Use | Example |\n",
    "|------------|-------------|----------|\n",
    "| **Flat/Uniform** | Truly no information | Beta(1, 1) for unknown probability |\n",
    "| **Weakly Informative** | Regularization, prevent extremes | Normal(0, 10) for regression coefficient |\n",
    "| **Informative** | Domain knowledge available | Normal(50, 5) for corn seasonal peak |\n",
    "| **Strongly Informative** | Physical/economic constraints | Gamma(100, 2) for volatility (must be positive) |\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "Recall Bayes' theorem:\n",
    "\n",
    "$$P(\\theta | \\text{Data}) \\propto P(\\text{Data} | \\theta) \\cdot P(\\theta)$$\n",
    "\n",
    "The prior $P(\\theta)$ can be:\n",
    "- **Uninformative**: $P(\\theta) \\propto$ constant (equal weight to all values)\n",
    "- **Weakly informative**: $P(\\theta)$ gently favors reasonable values\n",
    "- **Informative**: $P(\\theta)$ concentrates probability mass around expert beliefs\n",
    "\n",
    "**Key insight**: The influence of the prior decreases as $n$ (sample size) increases, but with limited commodity data, priors matter significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the prior spectrum for a regression coefficient\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "x = np.linspace(-30, 30, 1000)\n",
    "\n",
    "priors = [\n",
    "    (\"Flat Prior\", stats.uniform(-30, 60), \"No prior knowledge\"),\n",
    "    (\"Weakly Informative\", stats.norm(0, 10), \"Mild regularization\"),\n",
    "    (\"Informative\", stats.norm(0, 3), \"Some domain knowledge\"),\n",
    "    (\"Strongly Informative\", stats.norm(2, 0.5), \"Strong expert belief\")\n",
    "]\n",
    "\n",
    "for ax, (title, prior, description) in zip(axes.flatten(), priors):\n",
    "    if isinstance(prior, stats._continuous_distns.uniform_gen):\n",
    "        pdf_vals = prior.pdf(x, -30, 60)\n",
    "    else:\n",
    "        pdf_vals = prior.pdf(x)\n",
    "    \n",
    "    ax.plot(x, pdf_vals, 'blue', linewidth=2.5)\n",
    "    ax.fill_between(x, pdf_vals, alpha=0.3, color='blue')\n",
    "    ax.axvline(0, color='red', linestyle='--', alpha=0.5, label='Zero effect')\n",
    "    ax.set_title(f\"{title}\\n{description}\", fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Coefficient Value (β)', fontsize=11)\n",
    "    ax.set_ylabel('Probability Density', fontsize=11)\n",
    "    ax.set_xlim(-30, 30)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"1. Flat prior: All values equally likely (rarely appropriate)\")\n",
    "print(\"2. Weakly informative: Gently discourages extreme values\")\n",
    "print(\"3. Informative: Clear preference for values near zero\")\n",
    "print(\"4. Strongly informative: Almost certain the value is around 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conjugate Priors: Mathematical Elegance Meets Computational Efficiency\n",
    "\n",
    "A **conjugate prior** is a prior distribution that, when combined with a specific likelihood, produces a posterior in the same distributional family. This allows for closed-form Bayesian updates without MCMC.\n",
    "\n",
    "### Three Essential Conjugate Pairs for Commodities\n",
    "\n",
    "#### 2.1 Beta-Binomial: Win Rates and Directional Forecasts\n",
    "\n",
    "**Use case**: Probability of price increases, directional forecast accuracy\n",
    "\n",
    "$$\\begin{align}\n",
    "\\text{Prior: } & p \\sim \\text{Beta}(\\alpha, \\beta) \\\\\n",
    "\\text{Likelihood: } & X \\sim \\text{Binomial}(n, p) \\\\\n",
    "\\text{Posterior: } & p | X \\sim \\text{Beta}(\\alpha + x, \\beta + n - x)\n",
    "\\end{align}$$\n",
    "\n",
    "**Hyperparameter interpretation**:\n",
    "- $\\alpha$ = prior \"successes\" (e.g., days corn price rose)\n",
    "- $\\beta$ = prior \"failures\" (e.g., days corn price fell)\n",
    "- Prior mean: $\\mu = \\frac{\\alpha}{\\alpha + \\beta}$\n",
    "- Prior strength: $\\alpha + \\beta$ (larger = stronger prior)\n",
    "\n",
    "#### 2.2 Normal-Normal: Price Levels and Returns\n",
    "\n",
    "**Use case**: Estimating mean return, average price level\n",
    "\n",
    "$$\\begin{align}\n",
    "\\text{Prior: } & \\mu \\sim N(\\mu_0, \\sigma_0^2) \\\\\n",
    "\\text{Likelihood: } & X_i \\sim N(\\mu, \\sigma^2) \\text{ (known variance)} \\\\\n",
    "\\text{Posterior: } & \\mu | X \\sim N(\\mu_n, \\sigma_n^2)\n",
    "\\end{align}$$\n",
    "\n",
    "where:\n",
    "$$\\mu_n = \\frac{\\frac{\\mu_0}{\\sigma_0^2} + \\frac{n\\bar{x}}{\\sigma^2}}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}, \\quad \\sigma_n^2 = \\frac{1}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}$$\n",
    "\n",
    "**Interpretation**: Posterior mean is a **precision-weighted average** of prior mean and sample mean.\n",
    "\n",
    "#### 2.3 Gamma-Poisson: Event Counts\n",
    "\n",
    "**Use case**: Number of price spikes per month, supply disruption events\n",
    "\n",
    "$$\\begin{align}\n",
    "\\text{Prior: } & \\lambda \\sim \\text{Gamma}(\\alpha, \\beta) \\\\\n",
    "\\text{Likelihood: } & X \\sim \\text{Poisson}(\\lambda) \\\\\n",
    "\\text{Posterior: } & \\lambda | X \\sim \\text{Gamma}(\\alpha + \\sum x_i, \\beta + n)\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Beta-Binomial for directional forecasting\n",
    "# Scenario: Estimating probability that corn price rises in June (pre-harvest)\n",
    "\n",
    "def beta_binomial_update(prior_alpha, prior_beta, successes, trials):\n",
    "    \"\"\"\n",
    "    Perform Beta-Binomial conjugate update.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with prior, posterior, and statistics\n",
    "    \"\"\"\n",
    "    # Prior\n",
    "    prior = stats.beta(prior_alpha, prior_beta)\n",
    "    \n",
    "    # Posterior (conjugate update)\n",
    "    post_alpha = prior_alpha + successes\n",
    "    post_beta = prior_beta + (trials - successes)\n",
    "    posterior = stats.beta(post_alpha, post_beta)\n",
    "    \n",
    "    return {\n",
    "        'prior': prior,\n",
    "        'posterior': posterior,\n",
    "        'prior_mean': prior.mean(),\n",
    "        'posterior_mean': posterior.mean(),\n",
    "        'prior_std': prior.std(),\n",
    "        'posterior_std': posterior.std(),\n",
    "        'credible_interval': (posterior.ppf(0.025), posterior.ppf(0.975))\n",
    "    }\n",
    "\n",
    "# Prior belief: Corn rises in June about 60% of the time (historical knowledge)\n",
    "# We're moderately confident: equivalent to seeing 12 rises in 20 Junes\n",
    "prior_alpha = 12\n",
    "prior_beta = 8\n",
    "\n",
    "# New data: Last 10 years, corn rose in 7 Junes\n",
    "successes = 7\n",
    "trials = 10\n",
    "\n",
    "result = beta_binomial_update(prior_alpha, prior_beta, successes, trials)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.linspace(0, 1, 1000)\n",
    "\n",
    "ax.plot(x, result['prior'].pdf(x), 'orange', linewidth=2.5, \n",
    "        label=f\"Prior: Beta({prior_alpha}, {prior_beta}), mean={result['prior_mean']:.2f}\")\n",
    "ax.plot(x, result['posterior'].pdf(x), 'blue', linewidth=2.5,\n",
    "        label=f\"Posterior: mean={result['posterior_mean']:.2f}\")\n",
    "ax.axvline(0.5, color='red', linestyle='--', alpha=0.5, label='50% (random)')\n",
    "ax.fill_between(x, result['posterior'].pdf(x), alpha=0.2, color='blue')\n",
    "\n",
    "ax.set_xlabel('Probability Corn Rises in June', fontsize=12)\n",
    "ax.set_ylabel('Probability Density', fontsize=12)\n",
    "ax.set_title('Beta-Binomial Conjugate Update: Corn June Seasonality', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_xlim(0.3, 0.9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BETA-BINOMIAL CONJUGATE UPDATE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Prior belief: Corn rises in June {result['prior_mean']:.1%} of the time\")\n",
    "print(f\"Prior uncertainty: ± {result['prior_std']:.1%}\")\n",
    "print(f\"\\nObserved data: {successes} rises in {trials} Junes\")\n",
    "print(f\"\\nPosterior belief: {result['posterior_mean']:.1%}\")\n",
    "print(f\"Posterior uncertainty: ± {result['posterior_std']:.1%}\")\n",
    "print(f\"95% Credible Interval: [{result['credible_interval'][0]:.1%}, {result['credible_interval'][1]:.1%}]\")\n",
    "print(f\"\\nInterpretation: Updated belief is weighted average of prior and data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Normal-Normal for crude oil mean price\n",
    "# Scenario: Estimate mean WTI crude price with prior from expert knowledge\n",
    "\n",
    "def normal_normal_update(prior_mean, prior_std, data, data_std):\n",
    "    \"\"\"\n",
    "    Normal-Normal conjugate update (known variance case).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    prior_mean : float\n",
    "        Prior belief about mean\n",
    "    prior_std : float  \n",
    "        Prior uncertainty\n",
    "    data : array\n",
    "        Observed data\n",
    "    data_std : float\n",
    "        Known standard deviation of data\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    data_mean = np.mean(data)\n",
    "    \n",
    "    # Prior precision (inverse variance)\n",
    "    prior_precision = 1 / prior_std**2\n",
    "    data_precision = n / data_std**2\n",
    "    \n",
    "    # Posterior parameters\n",
    "    post_precision = prior_precision + data_precision\n",
    "    post_mean = (prior_precision * prior_mean + data_precision * data_mean) / post_precision\n",
    "    post_std = np.sqrt(1 / post_precision)\n",
    "    \n",
    "    return {\n",
    "        'prior': stats.norm(prior_mean, prior_std),\n",
    "        'posterior': stats.norm(post_mean, post_std),\n",
    "        'prior_mean': prior_mean,\n",
    "        'posterior_mean': post_mean,\n",
    "        'prior_std': prior_std,\n",
    "        'posterior_std': post_std,\n",
    "        'data_mean': data_mean,\n",
    "        'credible_interval': (post_mean - 1.96*post_std, post_mean + 1.96*post_std)\n",
    "    }\n",
    "\n",
    "# Prior: Expert believes WTI crude should be around $65, but uncertain (±$15)\n",
    "prior_mean = 65\n",
    "prior_std = 15\n",
    "\n",
    "# Data: Last 30 days average price\n",
    "np.random.seed(42)\n",
    "true_price = 72\n",
    "data_std = 8  # Known daily volatility\n",
    "observed_prices = np.random.normal(true_price, data_std, 30)\n",
    "\n",
    "result = normal_normal_update(prior_mean, prior_std, observed_prices, data_std)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.linspace(30, 100, 1000)\n",
    "\n",
    "ax.plot(x, result['prior'].pdf(x), 'orange', linewidth=2.5,\n",
    "        label=f\"Prior: N({prior_mean}, {prior_std}²)\")\n",
    "ax.axvline(result['data_mean'], color='green', linestyle=':', linewidth=2,\n",
    "          label=f\"Sample Mean: ${result['data_mean']:.2f}\")\n",
    "ax.plot(x, result['posterior'].pdf(x), 'blue', linewidth=2.5,\n",
    "        label=f\"Posterior: N({result['posterior_mean']:.1f}, {result['posterior_std']:.1f}²)\")\n",
    "ax.fill_between(x, result['posterior'].pdf(x), alpha=0.2, color='blue')\n",
    "\n",
    "ax.set_xlabel('WTI Crude Price ($/barrel)', fontsize=12)\n",
    "ax.set_ylabel('Probability Density', fontsize=12)\n",
    "ax.set_title('Normal-Normal Conjugate Update: WTI Crude Mean Price', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"NORMAL-NORMAL CONJUGATE UPDATE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Prior belief: Mean price = ${prior_mean:.2f} ± ${prior_std:.2f}\")\n",
    "print(f\"Sample mean: ${result['data_mean']:.2f} (n={len(observed_prices)} days)\")\n",
    "print(f\"\\nPosterior: Mean price = ${result['posterior_mean']:.2f} ± ${result['posterior_std']:.2f}\")\n",
    "print(f\"95% Credible Interval: [${result['credible_interval'][0]:.2f}, ${result['credible_interval'][1]:.2f}]\")\n",
    "print(f\"\\nNotice: Posterior is between prior and sample mean (precision-weighted)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insight: Conjugacy = Speed\n",
    "\n",
    "With conjugate priors:\n",
    "- **No MCMC needed**: Instant analytical updates\n",
    "- **Interpretable**: Clear relationship between prior and posterior\n",
    "- **Scalable**: Can update sequentially as new data arrives\n",
    "\n",
    "**When to use conjugate priors**:\n",
    "- Real-time trading systems (low latency)\n",
    "- Simple models where conjugacy applies\n",
    "- Teaching/prototyping before complex models\n",
    "\n",
    "**When NOT to use**:\n",
    "- Complex hierarchical models\n",
    "- Non-standard likelihoods\n",
    "- When you want maximum modeling flexibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prior Elicitation from Historical Data\n",
    "\n",
    "**The challenge**: How do you convert \"corn is volatile in August\" into a prior distribution?\n",
    "\n",
    "### Strategy 1: Empirical Bayes (Use the Data Twice)\n",
    "\n",
    "Use historical data to set hyperparameters, then use recent data for likelihood:\n",
    "\n",
    "1. Calculate historical volatility: $\\sigma_{\\text{hist}} = \\text{std}(\\text{returns}_{2000-2015})$\n",
    "2. Set prior: $\\sigma \\sim \\text{Half-Normal}(\\sigma_{\\text{hist}})$\n",
    "3. Update with recent data: returns$_{2020-2024}$\n",
    "\n",
    "**Pros**: Data-driven, objective  \n",
    "**Cons**: \"Uses data twice,\" not fully Bayesian\n",
    "\n",
    "### Strategy 2: Expert Elicitation\n",
    "\n",
    "Ask domain experts to specify:\n",
    "- \"What's your best guess for average June corn price?\" → prior mean\n",
    "- \"What range would you be 90% confident includes the true value?\" → prior variance\n",
    "\n",
    "### Strategy 3: Maximum Entropy Priors\n",
    "\n",
    "Choose the prior with maximum entropy subject to constraints (e.g., mean, variance). This represents \"least informative\" prior given constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Eliciting volatility prior from historical corn data\n",
    "\n",
    "# Simulate historical corn price returns (2000-2015)\n",
    "np.random.seed(42)\n",
    "historical_vol = 0.25  # True historical volatility\n",
    "n_hist = 250 * 15  # 15 years of daily data\n",
    "historical_returns = np.random.normal(0, historical_vol, n_hist)\n",
    "\n",
    "# Calculate empirical statistics\n",
    "empirical_mean = np.mean(historical_returns)\n",
    "empirical_std = np.std(historical_returns, ddof=1)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PRIOR ELICITATION: Corn Volatility\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Historical data: {n_hist:,} daily returns (2000-2015)\")\n",
    "print(f\"\\nEmpirical mean return: {empirical_mean:.4f}\")\n",
    "print(f\"Empirical volatility (std): {empirical_std:.4f}\")\n",
    "print(f\"\\nPrior specification:\")\n",
    "print(f\"  Mean return: μ ~ Normal(0, 0.01)  [weakly informative, expect ~0]\")\n",
    "print(f\"  Volatility: σ ~ Half-Normal({empirical_std:.3f})  [from historical data]\")\n",
    "\n",
    "# Visualize the elicited volatility prior\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Historical returns distribution\n",
    "ax = axes[0]\n",
    "ax.hist(historical_returns, bins=50, density=True, alpha=0.6, color='blue', label='Historical returns')\n",
    "x_range = np.linspace(-1, 1, 1000)\n",
    "ax.plot(x_range, stats.norm(0, empirical_std).pdf(x_range), 'red', linewidth=2, \n",
    "        label=f'Fitted Normal(0, {empirical_std:.3f})')\n",
    "ax.set_xlabel('Daily Return', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('Historical Returns Distribution', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.set_xlim(-1, 1)\n",
    "\n",
    "# Elicited volatility prior\n",
    "ax = axes[1]\n",
    "vol_range = np.linspace(0, 0.6, 1000)\n",
    "# Half-Normal prior for volatility\n",
    "prior_vol = stats.halfnorm(scale=empirical_std)\n",
    "ax.plot(vol_range, prior_vol.pdf(vol_range), 'orange', linewidth=2.5,\n",
    "        label=f'Prior: Half-Normal(σ={empirical_std:.3f})')\n",
    "ax.axvline(empirical_std, color='red', linestyle='--', linewidth=2, label='Historical estimate')\n",
    "ax.fill_between(vol_range, prior_vol.pdf(vol_range), alpha=0.3, color='orange')\n",
    "ax.set_xlabel('Volatility (σ)', fontsize=12)\n",
    "ax.set_ylabel('Probability Density', fontsize=12)\n",
    "ax.set_title('Elicited Volatility Prior', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPrior predictive check: Generate returns from prior\")\n",
    "# Sample from prior\n",
    "n_prior_samples = 1000\n",
    "prior_vol_samples = prior_vol.rvs(n_prior_samples)\n",
    "print(f\"Prior volatility samples: mean={np.mean(prior_vol_samples):.3f}, \"\n",
    "      f\"90% interval=[{np.percentile(prior_vol_samples, 5):.3f}, {np.percentile(prior_vol_samples, 95):.3f}]\")\n",
    "print(f\"This captures our uncertainty about true volatility before seeing recent data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Weakly Informative vs Informative Priors\n",
    "\n",
    "### Weakly Informative Priors: The Goldilocks Zone\n",
    "\n",
    "**Goal**: Regularize the model without imposing strong beliefs\n",
    "\n",
    "**Characteristics**:\n",
    "- Wide enough to not bias estimates\n",
    "- Narrow enough to rule out nonsense values\n",
    "- Often used for nuisance parameters\n",
    "\n",
    "**Examples**:\n",
    "- Regression coefficient: $\\beta \\sim N(0, 10)$ \n",
    "  - Allows large effects if data supports it\n",
    "  - But coefficients of 100 are implausible\n",
    "- Volatility: $\\sigma \\sim \\text{Half-Cauchy}(0, 2.5)$\n",
    "  - Heavy tails allow high volatility if needed\n",
    "  - But infinite volatility ruled out\n",
    "\n",
    "### Informative Priors: Encoding Real Knowledge\n",
    "\n",
    "**When to use**:\n",
    "- Strong domain expertise exists\n",
    "- Physical/economic constraints apply\n",
    "- Regularizing against overfitting to noise\n",
    "\n",
    "**Commodity examples**:\n",
    "- **Seasonal amplitude**: Historical seasonality rarely exceeds ±15%\n",
    "  - Prior: $A \\sim N(0, 0.10)$ (10% seasonal swing)\n",
    "- **Mean reversion speed**: Economics suggests λ ∈ [0.1, 1] per year\n",
    "  - Prior: $\\lambda \\sim \\text{Beta}(2, 2)$ rescaled to [0, 1]\n",
    "- **Oil price floor**: Can't go negative (pre-2020!), marginal cost ~$40\n",
    "  - Prior: $P_{\\text{min}} \\sim \\text{Truncated-Normal}(40, 10, \\text{lower}=0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare weakly informative vs informative priors with limited data\n",
    "\n",
    "# Scenario: Estimating seasonal effect in natural gas prices (winter spike)\n",
    "# True effect: +20% in winter\n",
    "\n",
    "np.random.seed(42)\n",
    "true_seasonal_effect = 0.20\n",
    "n_observations = 15  # Only 15 winters of data\n",
    "\n",
    "# Generate noisy observations\n",
    "observed_effects = np.random.normal(true_seasonal_effect, 0.15, n_observations)\n",
    "\n",
    "# Define priors\n",
    "priors = {\n",
    "    'Weakly Informative': stats.norm(0, 0.50),  # Wide, centered at zero\n",
    "    'Informative': stats.norm(0.15, 0.10),      # Based on historical knowledge\n",
    "}\n",
    "\n",
    "# Calculate posteriors (assuming known std of 0.15)\n",
    "data_mean = np.mean(observed_effects)\n",
    "data_std = 0.15\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "x = np.linspace(-0.3, 0.7, 1000)\n",
    "\n",
    "for ax, (name, prior) in zip(axes, priors.items()):\n",
    "    # Update using Normal-Normal conjugacy\n",
    "    prior_mean = prior.mean()\n",
    "    prior_std = prior.std()\n",
    "    \n",
    "    prior_prec = 1 / prior_std**2\n",
    "    data_prec = n_observations / data_std**2\n",
    "    \n",
    "    post_prec = prior_prec + data_prec\n",
    "    post_mean = (prior_prec * prior_mean + data_prec * data_mean) / post_prec\n",
    "    post_std = np.sqrt(1 / post_prec)\n",
    "    \n",
    "    posterior = stats.norm(post_mean, post_std)\n",
    "    \n",
    "    # Plot\n",
    "    ax.plot(x, prior.pdf(x), 'orange', linewidth=2, label='Prior')\n",
    "    ax.axvline(data_mean, color='green', linestyle=':', linewidth=2, label=f'Data mean ({data_mean:.2f})')\n",
    "    ax.plot(x, posterior.pdf(x), 'blue', linewidth=2, label='Posterior')\n",
    "    ax.axvline(true_seasonal_effect, color='red', linestyle='--', linewidth=2, label=f'True effect ({true_seasonal_effect:.0%})')\n",
    "    ax.fill_between(x, posterior.pdf(x), alpha=0.2, color='blue')\n",
    "    \n",
    "    ax.set_xlabel('Seasonal Effect', fontsize=12)\n",
    "    ax.set_ylabel('Density', fontsize=12)\n",
    "    ax.set_title(f'{name} Prior\\nPost. Mean: {post_mean:.2f} ± {post_std:.2f}', \n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.set_xlim(-0.3, 0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PRIOR STRENGTH COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(f\"True seasonal effect: {true_seasonal_effect:.0%}\")\n",
    "print(f\"Observed data mean: {data_mean:.2f} (n={n_observations})\")\n",
    "print(f\"\\nWith limited data, the informative prior pulls estimate closer to truth!\")\n",
    "print(f\"This is regularization in action.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prior Predictive Checks: Validating Your Priors\n",
    "\n",
    "**The question**: Before seeing any data, does my prior generate realistic data?\n",
    "\n",
    "### Prior Predictive Distribution\n",
    "\n",
    "$$P(\\tilde{y}) = \\int P(\\tilde{y} | \\theta) P(\\theta) d\\theta$$\n",
    "\n",
    "In words: Average the likelihood over all possible parameter values weighted by the prior.\n",
    "\n",
    "### Workflow:\n",
    "\n",
    "1. **Sample** parameter values from prior: $\\theta^{(1)}, \\ldots, \\theta^{(N)} \\sim P(\\theta)$\n",
    "2. For each $\\theta^{(i)}$, **generate** fake data: $\\tilde{y}^{(i)} \\sim P(y | \\theta^{(i)})$\n",
    "3. **Inspect** simulated datasets:\n",
    "   - Do they look like real commodity data?\n",
    "   - Are the ranges reasonable?\n",
    "   - Do they exhibit expected features (volatility clustering, seasonality)?\n",
    "\n",
    "### Red Flags:\n",
    "\n",
    "- Simulated prices go negative (need positivity constraint)\n",
    "- Volatility is 500% (unrealistic for most commodities)\n",
    "- No seasonal patterns when you expect them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior predictive check for corn price model\n",
    "# Model: log(Price_t) = μ + β*sin(2π*t/365) + ε, where ε ~ N(0, σ)\n",
    "\n",
    "# Define priors\n",
    "prior_mu = stats.norm(np.log(400), 0.3)       # Mean log-price around $400/bushel\n",
    "prior_beta = stats.norm(0, 0.15)              # Seasonal amplitude (15% swing)\n",
    "prior_sigma = stats.halfnorm(scale=0.10)      # Daily volatility\n",
    "\n",
    "# Prior predictive sampling\n",
    "n_prior_samples = 100\n",
    "n_days = 365 * 2  # 2 years\n",
    "t = np.arange(n_days)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Generate prior predictive samples\n",
    "for i in range(n_prior_samples):\n",
    "    # Sample parameters from priors\n",
    "    mu_sample = prior_mu.rvs()\n",
    "    beta_sample = prior_beta.rvs()\n",
    "    sigma_sample = prior_sigma.rvs()\n",
    "    \n",
    "    # Generate data from model\n",
    "    seasonal_component = beta_sample * np.sin(2 * np.pi * t / 365)\n",
    "    noise = np.random.normal(0, sigma_sample, n_days)\n",
    "    log_price = mu_sample + seasonal_component + noise\n",
    "    price = np.exp(log_price)\n",
    "    \n",
    "    # Plot\n",
    "    axes[0].plot(t, price, alpha=0.3, color='blue', linewidth=0.5)\n",
    "\n",
    "axes[0].set_xlabel('Days', fontsize=12)\n",
    "axes[0].set_ylabel('Corn Price (¢/bushel)', fontsize=12)\n",
    "axes[0].set_title('Prior Predictive Check: Simulated Corn Prices from Prior', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylim(200, 800)\n",
    "axes[0].axhline(400, color='red', linestyle='--', alpha=0.5, label='Expected mean price')\n",
    "axes[0].legend()\n",
    "\n",
    "# Distribution of simulated prices at a single time point\n",
    "simulated_prices_t0 = []\n",
    "for i in range(5000):\n",
    "    mu_sample = prior_mu.rvs()\n",
    "    beta_sample = prior_beta.rvs()\n",
    "    sigma_sample = prior_sigma.rvs()\n",
    "    log_price = mu_sample + beta_sample * np.sin(0) + np.random.normal(0, sigma_sample)\n",
    "    simulated_prices_t0.append(np.exp(log_price))\n",
    "\n",
    "axes[1].hist(simulated_prices_t0, bins=50, density=True, alpha=0.6, color='blue',\n",
    "            label='Prior predictive distribution')\n",
    "axes[1].axvline(400, color='red', linestyle='--', linewidth=2, label='Expected mean')\n",
    "axes[1].set_xlabel('Corn Price (¢/bushel)', fontsize=12)\n",
    "axes[1].set_ylabel('Density', fontsize=12)\n",
    "axes[1].set_title('Prior Predictive Distribution at t=0', fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].set_xlim(150, 800)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PRIOR PREDICTIVE CHECK INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nSimulated price range: ${np.percentile(simulated_prices_t0, 1):.0f} - ${np.percentile(simulated_prices_t0, 99):.0f}\")\n",
    "print(f\"Median: ${np.median(simulated_prices_t0):.0f}\")\n",
    "print(f\"\\nQuestions to ask:\")\n",
    "print(f\"  1. Do these prices look realistic? ✓ (corn trades $300-600 typically)\")\n",
    "print(f\"  2. Is seasonality visible? ✓ (smooth annual cycles)\")\n",
    "print(f\"  3. Are there negative prices? ✗ (log-scale prevents this)\")\n",
    "print(f\"  4. Is volatility reasonable? ✓ (not too wild)\")\n",
    "print(f\"\\nConclusion: Prior seems reasonable! Proceed to fit model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prior Sensitivity Analysis\n",
    "\n",
    "**The concern**: What if my prior is wrong? Will it ruin my conclusions?\n",
    "\n",
    "### Sensitivity Analysis Workflow\n",
    "\n",
    "1. **Fit model** with your chosen prior\n",
    "2. **Refit** with several alternative priors:\n",
    "   - More skeptical (narrower)\n",
    "   - More vague (wider)\n",
    "   - Different center\n",
    "3. **Compare** posterior inferences:\n",
    "   - Do point estimates change substantially?\n",
    "   - Do credible intervals overlap?\n",
    "   - Do trading decisions change?\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **Robust**: Conclusions similar across priors → data dominates\n",
    "- **Sensitive**: Conclusions vary widely → need more data or justify prior choice\n",
    "\n",
    "**Trading rule**: If your P&L depends critically on prior choice, you don't have enough data to trade this strategy yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior sensitivity analysis: Does conclusion depend on prior?\n",
    "# Scenario: Is natural gas seasonal spike > 10%?\n",
    "\n",
    "np.random.seed(42)\n",
    "true_effect = 0.18\n",
    "n_obs = 20\n",
    "observed_data = np.random.normal(true_effect, 0.08, n_obs)\n",
    "data_mean = np.mean(observed_data)\n",
    "data_std = 0.08\n",
    "\n",
    "# Test multiple priors\n",
    "prior_scenarios = {\n",
    "    'Skeptical': stats.norm(0.05, 0.05),\n",
    "    'Neutral': stats.norm(0.10, 0.10),\n",
    "    'Optimistic': stats.norm(0.20, 0.08),\n",
    "    'Vague': stats.norm(0, 0.50),\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "x = np.linspace(-0.1, 0.5, 1000)\n",
    "\n",
    "results = {}\n",
    "for ax, (name, prior) in zip(axes.flatten(), prior_scenarios.items()):\n",
    "    # Conjugate update\n",
    "    prior_mean = prior.mean()\n",
    "    prior_std = prior.std()\n",
    "    \n",
    "    prior_prec = 1 / prior_std**2\n",
    "    data_prec = n_obs / data_std**2\n",
    "    \n",
    "    post_prec = prior_prec + data_prec\n",
    "    post_mean = (prior_prec * prior_mean + data_prec * data_mean) / post_prec\n",
    "    post_std = np.sqrt(1 / post_prec)\n",
    "    \n",
    "    posterior = stats.norm(post_mean, post_std)\n",
    "    \n",
    "    # Calculate P(effect > 10%)\n",
    "    prob_above_10 = 1 - posterior.cdf(0.10)\n",
    "    \n",
    "    results[name] = {\n",
    "        'posterior_mean': post_mean,\n",
    "        'posterior_std': post_std,\n",
    "        'prob_above_10': prob_above_10\n",
    "    }\n",
    "    \n",
    "    # Plot\n",
    "    ax.plot(x, prior.pdf(x), 'orange', linewidth=2, label='Prior')\n",
    "    ax.plot(x, posterior.pdf(x), 'blue', linewidth=2, label='Posterior')\n",
    "    ax.axvline(0.10, color='red', linestyle='--', linewidth=2, label='10% threshold')\n",
    "    ax.fill_betweenx([0, ax.get_ylim()[1]], 0.10, 0.5, alpha=0.1, color='green')\n",
    "    ax.axvline(data_mean, color='green', linestyle=':', linewidth=1.5, alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Seasonal Effect', fontsize=11)\n",
    "    ax.set_ylabel('Density', fontsize=11)\n",
    "    ax.set_title(f'{name} Prior\\nP(effect > 10%) = {prob_above_10:.1%}', \n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.set_xlim(-0.1, 0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"=\"*70)\n",
    "print(\"PRIOR SENSITIVITY ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nObserved data: mean = {data_mean:.2f}, n = {n_obs}\")\n",
    "print(f\"True effect: {true_effect:.0%}\\n\")\n",
    "print(f\"{'Prior':<15} {'Post. Mean':>12} {'Post. Std':>12} {'P(>10%)':>12}\")\n",
    "print(\"-\"*70)\n",
    "for name, res in results.items():\n",
    "    print(f\"{name:<15} {res['posterior_mean']:>12.2f} {res['posterior_std']:>12.3f} {res['prob_above_10']:>12.1%}\")\n",
    "\n",
    "print(f\"\\nConclusion: All priors lead to P(effect > 10%) > 90%\")\n",
    "print(f\"Result is ROBUST to prior choice - data dominates!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Practical Application: Encoding Corn Seasonality\n",
    "\n",
    "Let's apply everything we've learned to a realistic commodity trading problem.\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "You're building a model to forecast corn prices. You know:\n",
    "- Corn has strong seasonality (planting in spring, harvest in fall)\n",
    "- Prices typically peak in June-July (pre-harvest fear of supply shortage)\n",
    "- Prices typically bottom in October-November (post-harvest glut)\n",
    "\n",
    "### Model\n",
    "\n",
    "$$\\log(P_t) = \\mu + \\beta_1 \\sin\\left(\\frac{2\\pi t}{365}\\right) + \\beta_2 \\cos\\left(\\frac{2\\pi t}{365}\\right) + \\epsilon_t$$\n",
    "\n",
    "where:\n",
    "- $\\mu$ = baseline log-price\n",
    "- $\\beta_1, \\beta_2$ = seasonal coefficients\n",
    "- Seasonal amplitude = $\\sqrt{\\beta_1^2 + \\beta_2^2}$\n",
    "- Peak timing = $\\arctan(\\beta_2 / \\beta_1)$\n",
    "\n",
    "### Prior Selection\n",
    "\n",
    "From historical knowledge:\n",
    "- Average price: ~$4.00/bushel → $\\mu \\sim N(\\log(4), 0.2)$\n",
    "- Seasonal swing: 10-15% → $\\beta_1, \\beta_2 \\sim N(0, 0.10)$\n",
    "- Volatility: 20-30% annualized → $\\sigma \\sim \\text{Half-Normal}(0.25/\\sqrt{252})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full seasonal model for corn prices\n",
    "\n",
    "# Generate synthetic corn price data with known seasonality\n",
    "np.random.seed(42)\n",
    "n_days = 365 * 3  # 3 years\n",
    "t = np.arange(n_days)\n",
    "\n",
    "# True parameters\n",
    "true_mu = np.log(4.0)\n",
    "true_beta1 = 0.12  # Sin coefficient\n",
    "true_beta2 = 0.08  # Cos coefficient\n",
    "true_sigma = 0.015  # Daily volatility\n",
    "\n",
    "# Generate data\n",
    "seasonal = true_beta1 * np.sin(2*np.pi*t/365) + true_beta2 * np.cos(2*np.pi*t/365)\n",
    "noise = np.random.normal(0, true_sigma, n_days)\n",
    "log_prices = true_mu + seasonal + noise\n",
    "prices = np.exp(log_prices)\n",
    "\n",
    "# Design matrix for regression\n",
    "X = np.column_stack([\n",
    "    np.ones(n_days),                    # Intercept\n",
    "    np.sin(2*np.pi*t/365),              # Sin component\n",
    "    np.cos(2*np.pi*t/365)               # Cos component\n",
    "])\n",
    "y = log_prices\n",
    "\n",
    "# Bayesian linear regression with informative priors\n",
    "# Prior parameters\n",
    "prior_mean = np.array([np.log(4.0), 0, 0])  # μ, β1, β2\n",
    "prior_cov = np.diag([0.2**2, 0.10**2, 0.10**2])  # Diagonal covariance\n",
    "\n",
    "# Likelihood: y | β, σ² ~ N(Xβ, σ²I)\n",
    "# We'll use known σ² for conjugacy (in practice, estimate this too)\n",
    "sigma_sq = true_sigma**2\n",
    "\n",
    "# Posterior (Normal-Normal conjugate update for regression)\n",
    "# Posterior precision = Prior precision + Data precision\n",
    "prior_precision = np.linalg.inv(prior_cov)\n",
    "data_precision = X.T @ X / sigma_sq\n",
    "\n",
    "post_precision = prior_precision + data_precision\n",
    "post_cov = np.linalg.inv(post_precision)\n",
    "\n",
    "# Posterior mean = post_cov @ (prior_precision @ prior_mean + data_precision @ (X'y))\n",
    "post_mean = post_cov @ (prior_precision @ prior_mean + (X.T @ y) / sigma_sq)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BAYESIAN SEASONAL MODEL: Corn Prices\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTrue parameters:\")\n",
    "print(f\"  μ (log-price): {true_mu:.3f} → ${np.exp(true_mu):.2f}/bushel\")\n",
    "print(f\"  β₁ (sin): {true_beta1:.3f}\")\n",
    "print(f\"  β₂ (cos): {true_beta2:.3f}\")\n",
    "print(f\"  Amplitude: {np.sqrt(true_beta1**2 + true_beta2**2):.3f} ({100*np.sqrt(true_beta1**2 + true_beta2**2):.1f}%)\")\n",
    "\n",
    "print(f\"\\nPosterior estimates:\")\n",
    "print(f\"  μ: {post_mean[0]:.3f} ± {np.sqrt(post_cov[0,0]):.3f} → ${np.exp(post_mean[0]):.2f}/bushel\")\n",
    "print(f\"  β₁: {post_mean[1]:.3f} ± {np.sqrt(post_cov[1,1]):.3f}\")\n",
    "print(f\"  β₂: {post_mean[2]:.3f} ± {np.sqrt(post_cov[2,2]):.3f}\")\n",
    "amplitude_est = np.sqrt(post_mean[1]**2 + post_mean[2]**2)\n",
    "print(f\"  Amplitude: {amplitude_est:.3f} ({100*amplitude_est:.1f}%)\")\n",
    "\n",
    "# Fitted values\n",
    "fitted_log_prices = X @ post_mean\n",
    "fitted_prices = np.exp(fitted_log_prices)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Time series\n",
    "ax = axes[0]\n",
    "dates = pd.date_range('2021-01-01', periods=n_days, freq='D')\n",
    "ax.plot(dates, prices, 'o', alpha=0.3, markersize=2, label='Observed prices', color='blue')\n",
    "ax.plot(dates, fitted_prices, 'red', linewidth=2, label='Bayesian fit (posterior mean)')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Corn Price ($/bushel)', fontsize=12)\n",
    "ax.set_title('Corn Price Seasonality: Bayesian Regression', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Seasonal component only\n",
    "ax = axes[1]\n",
    "seasonal_component = post_mean[1] * np.sin(2*np.pi*t/365) + post_mean[2] * np.cos(2*np.pi*t/365)\n",
    "ax.plot(t % 365, seasonal_component, 'o', alpha=0.5, markersize=3, color='green')\n",
    "ax.axhline(0, color='black', linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('Day of Year', fontsize=12)\n",
    "ax.set_ylabel('Seasonal Effect (log-price)', fontsize=12)\n",
    "ax.set_title('Extracted Seasonal Pattern', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, 365)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Mark key agricultural dates\n",
    "key_dates = [\n",
    "    (120, 'Planting'),\n",
    "    (180, 'Peak (pre-harvest)'),\n",
    "    (280, 'Harvest'),\n",
    "]\n",
    "for day, label in key_dates:\n",
    "    ax.axvline(day, color='red', linestyle=':', alpha=0.7)\n",
    "    ax.text(day, ax.get_ylim()[1]*0.9, label, rotation=90, fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTrading insight: Seasonal pattern shows {amplitude_est:.1%} swing\")\n",
    "print(f\"Peak occurs around day {np.argmax(seasonal_component):.0f} (late June)\")\n",
    "print(f\"Trough occurs around day {np.argmin(seasonal_component):.0f} (late December)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary: The Art and Science of Prior Selection\n",
    "\n",
    "### Key Principles\n",
    "\n",
    "| Principle | Guidance |\n",
    "|-----------|----------|\n",
    "| **Honesty** | Priors should reflect genuine beliefs, not desired conclusions |\n",
    "| **Transparency** | Document and justify prior choices |\n",
    "| **Calibration** | Use prior predictive checks to validate |\n",
    "| **Sensitivity** | Test robustness to prior specification |\n",
    "| **Parsimony** | Use weakly informative priors when in doubt |\n",
    "\n",
    "### The Prior Selection Checklist\n",
    "\n",
    "Before finalizing priors:\n",
    "\n",
    "1. ✅ **Physical constraints**: Are negative prices/volatilities possible?\n",
    "2. ✅ **Domain knowledge**: What do experts believe?\n",
    "3. ✅ **Historical data**: What have we seen before?\n",
    "4. ✅ **Prior predictive**: Do simulations look realistic?\n",
    "5. ✅ **Sensitivity**: Do conclusions depend critically on prior?\n",
    "6. ✅ **Documentation**: Can someone else understand your choices?\n",
    "\n",
    "### Common Mistakes to Avoid\n",
    "\n",
    "- ❌ Using flat priors for unbounded parameters (they're not actually \"uninformative\")\n",
    "- ❌ Picking priors to get desired answers (confirmation bias)\n",
    "- ❌ Ignoring domain expertise when it exists\n",
    "- ❌ Using overly confident priors with limited justification\n",
    "- ❌ Failing to check prior predictive distributions\n",
    "\n",
    "### When Priors Matter Most\n",
    "\n",
    "- **Limited data**: < 100 observations\n",
    "- **High-dimensional models**: Many parameters relative to data\n",
    "- **Hierarchical models**: Priors on hyperparameters strongly influence results\n",
    "- **Risk management**: Tail probabilities sensitive to prior specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Knowledge Check Quiz\n",
    "\n",
    "**Q1**: A conjugate prior is valuable because:\n",
    "- A) It always gives the most accurate results\n",
    "- B) It allows closed-form posterior updates without MCMC\n",
    "- C) It's always the correct prior to use\n",
    "- D) It eliminates the need for data\n",
    "\n",
    "**Q2**: In a Beta-Binomial model, increasing the prior hyperparameters (α + β) makes the prior:\n",
    "- A) More influential (stronger)\n",
    "- B) Less influential (weaker)\n",
    "- C) Wider and more uncertain\n",
    "- D) Has no effect\n",
    "\n",
    "**Q3**: Prior predictive checks help you:\n",
    "- A) Calculate the posterior distribution\n",
    "- B) Determine if your prior generates realistic data\n",
    "- C) Avoid using priors altogether\n",
    "- D) Maximize the likelihood\n",
    "\n",
    "**Q4**: A weakly informative prior is appropriate when:\n",
    "- A) You have very strong domain knowledge\n",
    "- B) You want regularization without imposing strong beliefs\n",
    "- C) The data is highly informative\n",
    "- D) You want results identical to frequentist methods\n",
    "\n",
    "**Q5**: If your trading decision changes dramatically with different reasonable priors, you should:\n",
    "- A) Pick the prior that gives the best backtest results\n",
    "- B) Use a flat prior\n",
    "- C) Recognize you need more data or a stronger justification for your prior\n",
    "- D) Ignore the sensitivity and proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz Answers\n",
    "print(\"=\"*70)\n",
    "print(\"QUIZ ANSWERS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Q1: B) It allows closed-form posterior updates without MCMC\n",
    "    Conjugate priors provide computational efficiency through analytical\n",
    "    solutions. They're not always \"correct\" but are very useful.\n",
    "\n",
    "Q2: A) More influential (stronger)\n",
    "    α + β represents \"prior sample size.\" Larger values mean the prior\n",
    "    counts more relative to the data, making it stronger/more influential.\n",
    "\n",
    "Q3: B) Determine if your prior generates realistic data\n",
    "    Prior predictive checks sample from P(data|prior) to verify that\n",
    "    your prior can generate datasets that look like real commodity data.\n",
    "\n",
    "Q4: B) You want regularization without imposing strong beliefs\n",
    "    Weakly informative priors are the \"Goldilocks\" choice: they prevent\n",
    "    nonsense values without strongly biasing results.\n",
    "\n",
    "Q5: C) Recognize you need more data or a stronger justification for your prior\n",
    "    Prior sensitivity indicates conclusions aren't robust. Either collect\n",
    "    more data or carefully justify your prior choice. Never pick priors\n",
    "    to optimize backtests (overfitting)!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "Complete these exercises in the `exercises.ipynb` notebook.\n",
    "\n",
    "### Exercise 1: Conjugate Prior Derivation (Medium)\n",
    "Derive the posterior parameters for the Normal-Normal conjugate pair. Verify your derivation matches the formula in the notes.\n",
    "\n",
    "### Exercise 2: Agricultural Seasonality (Medium)\n",
    "Using the corn seasonality model, encode priors for wheat (different growing season). Wheat is planted in fall, harvested in summer. How should β₁ and β₂ change?\n",
    "\n",
    "### Exercise 3: Prior Sensitivity in Trading (Hard)\n",
    "You have a mean-reversion trading strategy. Build a model with a prior on the mean-reversion speed λ. Test sensitivity to three priors: skeptical (λ~0), moderate (λ~0.5), strong (λ~1). With only 50 trades, how much do P&L distributions differ?\n",
    "\n",
    "### Exercise 4: Prior Elicitation Interview (Hard)\n",
    "Interview a hypothetical crude oil expert to elicit a prior for next year's average price. Convert their qualitative statements into a Normal distribution:\n",
    "- \"Most likely around $75\"\n",
    "- \"Very unlikely to be below $50 or above $100\"\n",
    "- \"90% confident it's between $60 and $90\"\n",
    "\n",
    "---\n",
    "\n",
    "## Next Module Preview\n",
    "\n",
    "In **Module 3: MCMC and Computational Inference**, we'll learn:\n",
    "- Why conjugate priors aren't always possible\n",
    "- How MCMC algorithms sample from complex posteriors\n",
    "- Implementing Metropolis-Hastings from scratch\n",
    "- Using PyMC for production-grade Bayesian inference\n",
    "- Diagnosing convergence and sampling problems\n",
    "- Applying MCMC to real commodity price forecasting\n",
    "\n",
    "---\n",
    "\n",
    "*Module 2 Complete*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
