{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8: Gaussian Processes for Non-Linear Forecasting\n",
    "\n",
    "**Course**: Bayesian Regression and Time Series Forecasting for Commodities Trading\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this module, you will be able to:\n",
    "\n",
    "1. **Understand** Gaussian Process regression as a distribution over functions\n",
    "2. **Implement** different kernel functions (RBF, Matérn, Periodic) for various patterns\n",
    "3. **Build** GP models with PyMC for non-linear commodity price forecasting\n",
    "4. **Combine** multiple kernels to capture complex patterns (trend + seasonality + noise)\n",
    "5. **Optimize** hyperparameters and interpret their economic meaning\n",
    "6. **Apply** sparse approximations for computational efficiency with large datasets\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Matters for Trading\n",
    "\n",
    "Commodity prices often exhibit **complex non-linear patterns** that linear models cannot capture:\n",
    "\n",
    "- **Copper prices**: Gradual growth during economic expansion, sharp drops during recessions\n",
    "- **Natural gas**: Seasonal patterns with different amplitudes across years\n",
    "- **Coffee**: Multi-year cycles driven by planting and harvest dynamics\n",
    "- **Crude oil**: Regime changes from geopolitical events\n",
    "\n",
    "Gaussian Processes (GPs) offer several advantages for commodity trading:\n",
    "\n",
    "1. **Non-parametric flexibility**: Learn complex patterns without assuming functional form\n",
    "2. **Uncertainty quantification**: Full predictive distributions, not just point estimates\n",
    "3. **Kernel composition**: Combine seasonal, trend, and cyclical components naturally\n",
    "4. **Automatic smoothness**: Regularization through kernel hyperparameters\n",
    "5. **Prior knowledge**: Encode beliefs about smoothness, periodicity, and length scales\n",
    "\n",
    "**Real-world application**: A copper trader using GPs can:\n",
    "- Detect regime changes (e.g., China demand shocks)\n",
    "- Forecast with uncertainty bands for risk management\n",
    "- Identify when patterns deviate from historical behavior\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is a Gaussian Process?\n",
    "\n",
    "### 1.1 Intuition: A Distribution Over Functions\n",
    "\n",
    "**Standard regression**: We assume a functional form (linear, polynomial, etc.) and estimate parameters.\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\epsilon$$\n",
    "\n",
    "**Gaussian Process**: We place a prior directly over the **space of all possible functions**.\n",
    "\n",
    "A Gaussian Process is defined by:\n",
    "1. **Mean function** $m(x)$: Expected value of function at each point (often $m(x) = 0$)\n",
    "2. **Covariance function (kernel)** $k(x, x')$: How correlated are function values at $x$ and $x'$?\n",
    "\n",
    "$$f(x) \\sim \\mathcal{GP}(m(x), k(x, x'))$$\n",
    "\n",
    "For any finite set of points $\\{x_1, ..., x_n\\}$, the function values follow a multivariate normal:\n",
    "\n",
    "$$\\begin{bmatrix} f(x_1) \\\\ \\vdots \\\\ f(x_n) \\end{bmatrix} \\sim \\mathcal{N}\\left(\\begin{bmatrix} m(x_1) \\\\ \\vdots \\\\ m(x_n) \\end{bmatrix}, \\begin{bmatrix} k(x_1,x_1) & \\cdots & k(x_1,x_n) \\\\ \\vdots & \\ddots & \\vdots \\\\ k(x_n,x_1) & \\cdots & k(x_n,x_n) \\end{bmatrix}\\right)$$\n",
    "\n",
    "### 1.2 The Kernel's Role\n",
    "\n",
    "The kernel $k(x, x')$ encodes our **assumptions about smoothness**:\n",
    "\n",
    "- **Large $k(x, x')$**: Function values at $x$ and $x'$ are highly correlated\n",
    "- **Small $k(x, x')$**: Function values are nearly independent\n",
    "\n",
    "**Trading interpretation**: \n",
    "- High correlation → Smooth price evolution (gradual trends)\n",
    "- Low correlation → Rapid price changes (volatile markets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n",
    "print(f\"PyMC version: {pm.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Kernel Functions: Encoding Prior Beliefs\n",
    "\n",
    "Kernels are the heart of GP modeling. Different kernels capture different patterns.\n",
    "\n",
    "### 2.1 Radial Basis Function (RBF) / Squared Exponential\n",
    "\n",
    "$$k_{\\text{RBF}}(x, x') = \\sigma^2 \\exp\\left(-\\frac{(x - x')^2}{2\\ell^2}\\right)$$\n",
    "\n",
    "**Parameters**:\n",
    "- $\\sigma^2$ (amplitude): Variance of function values\n",
    "- $\\ell$ (length scale): How quickly correlation decays with distance\n",
    "\n",
    "**Properties**:\n",
    "- Infinitely differentiable (very smooth)\n",
    "- Universal approximator\n",
    "- Good for smooth trends\n",
    "\n",
    "**Trading use**: Modeling gradual price trends in commodities like copper, gold\n",
    "\n",
    "### 2.2 Matérn Kernel\n",
    "\n",
    "$$k_{\\text{Matérn}}(x, x') = \\sigma^2 \\frac{2^{1-\\nu}}{\\Gamma(\\nu)} \\left(\\sqrt{2\\nu}\\frac{|x-x'|}{\\ell}\\right)^\\nu K_\\nu\\left(\\sqrt{2\\nu}\\frac{|x-x'|}{\\ell}\\right)$$\n",
    "\n",
    "**Parameters**:\n",
    "- $\\nu$ (smoothness): Controls differentiability\n",
    "  - $\\nu = 0.5$: Rough (exponential kernel)\n",
    "  - $\\nu = 1.5$: Once differentiable\n",
    "  - $\\nu = 2.5$: Twice differentiable\n",
    "  - $\\nu \\to \\infty$: Converges to RBF\n",
    "\n",
    "**Trading use**: More realistic than RBF for commodity prices (finite differentiability)\n",
    "\n",
    "### 2.3 Periodic Kernel\n",
    "\n",
    "$$k_{\\text{Periodic}}(x, x') = \\sigma^2 \\exp\\left(-\\frac{2\\sin^2(\\pi |x-x'|/p)}{\\ell^2}\\right)$$\n",
    "\n",
    "**Parameters**:\n",
    "- $p$ (period): Length of one cycle\n",
    "- $\\ell$ (length scale): Smoothness within period\n",
    "\n",
    "**Trading use**: Natural gas seasonality, agricultural commodity cycles\n",
    "\n",
    "### 2.4 Rational Quadratic\n",
    "\n",
    "$$k_{\\text{RQ}}(x, x') = \\sigma^2 \\left(1 + \\frac{(x-x')^2}{2\\alpha\\ell^2}\\right)^{-\\alpha}$$\n",
    "\n",
    "**Properties**: Mixture of RBF kernels with different length scales\n",
    "\n",
    "**Trading use**: Multi-scale patterns (short-term noise + long-term trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_kernels():\n",
    "    \"\"\"\n",
    "    Visualize different kernel functions and their properties.\n",
    "    \"\"\"\n",
    "    # Create x points\n",
    "    x = np.linspace(0, 10, 200)\n",
    "    x_ref = 5.0  # Reference point\n",
    "    \n",
    "    # Define kernels\n",
    "    def rbf_kernel(x, x_ref, length_scale=1.0, amplitude=1.0):\n",
    "        return amplitude**2 * np.exp(-0.5 * (x - x_ref)**2 / length_scale**2)\n",
    "    \n",
    "    def matern_kernel(x, x_ref, length_scale=1.0, nu=1.5, amplitude=1.0):\n",
    "        # Simplified Matérn 3/2\n",
    "        r = np.abs(x - x_ref)\n",
    "        sqrt3_r = np.sqrt(3) * r / length_scale\n",
    "        return amplitude**2 * (1 + sqrt3_r) * np.exp(-sqrt3_r)\n",
    "    \n",
    "    def periodic_kernel(x, x_ref, period=2.0, length_scale=1.0, amplitude=1.0):\n",
    "        return amplitude**2 * np.exp(-2 * np.sin(np.pi * np.abs(x - x_ref) / period)**2 / length_scale**2)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(16, 9))\n",
    "    \n",
    "    # RBF with different length scales\n",
    "    ax = axes[0, 0]\n",
    "    for ls in [0.5, 1.0, 2.0]:\n",
    "        ax.plot(x, rbf_kernel(x, x_ref, length_scale=ls), label=f'ℓ = {ls}', linewidth=2)\n",
    "    ax.axvline(x_ref, color='red', linestyle='--', alpha=0.3)\n",
    "    ax.set_title('RBF Kernel: Length Scale Effect', fontweight='bold')\n",
    "    ax.set_xlabel('Distance from reference point')\n",
    "    ax.set_ylabel('Correlation')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Matérn with different smoothness\n",
    "    ax = axes[0, 1]\n",
    "    # Matérn 1/2 (exponential)\n",
    "    r = np.abs(x - x_ref)\n",
    "    ax.plot(x, np.exp(-r / 1.0), label='ν = 0.5 (rough)', linewidth=2)\n",
    "    ax.plot(x, matern_kernel(x, x_ref, length_scale=1.0), label='ν = 1.5 (smooth)', linewidth=2)\n",
    "    ax.plot(x, rbf_kernel(x, x_ref, length_scale=1.0), label='ν → ∞ (RBF)', linewidth=2, linestyle='--')\n",
    "    ax.axvline(x_ref, color='red', linestyle='--', alpha=0.3)\n",
    "    ax.set_title('Matérn Kernel: Smoothness Parameter', fontweight='bold')\n",
    "    ax.set_xlabel('Distance from reference point')\n",
    "    ax.set_ylabel('Correlation')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Periodic kernel\n",
    "    ax = axes[0, 2]\n",
    "    for period in [1.0, 2.0, 3.0]:\n",
    "        ax.plot(x, periodic_kernel(x, x_ref, period=period), label=f'Period = {period}', linewidth=2)\n",
    "    ax.axvline(x_ref, color='red', linestyle='--', alpha=0.3)\n",
    "    ax.set_title('Periodic Kernel: Period Effect', fontweight='bold')\n",
    "    ax.set_xlabel('Distance from reference point')\n",
    "    ax.set_ylabel('Correlation')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Sample functions from GP priors\n",
    "    n_samples = 5\n",
    "    x_sample = np.linspace(0, 10, 100)\n",
    "    \n",
    "    # RBF samples\n",
    "    ax = axes[1, 0]\n",
    "    K = rbf_kernel(x_sample[:, None], x_sample[None, :], length_scale=1.0)\n",
    "    samples = np.random.multivariate_normal(np.zeros(len(x_sample)), K + 1e-6*np.eye(len(x_sample)), n_samples)\n",
    "    for i in range(n_samples):\n",
    "        ax.plot(x_sample, samples[i], alpha=0.7, linewidth=1.5)\n",
    "    ax.set_title('Functions from RBF Prior', fontweight='bold')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('f(x)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Matérn samples\n",
    "    ax = axes[1, 1]\n",
    "    K = matern_kernel(x_sample[:, None], x_sample[None, :], length_scale=1.0)\n",
    "    samples = np.random.multivariate_normal(np.zeros(len(x_sample)), K + 1e-6*np.eye(len(x_sample)), n_samples)\n",
    "    for i in range(n_samples):\n",
    "        ax.plot(x_sample, samples[i], alpha=0.7, linewidth=1.5)\n",
    "    ax.set_title('Functions from Matérn Prior', fontweight='bold')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('f(x)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Periodic samples\n",
    "    ax = axes[1, 2]\n",
    "    K = periodic_kernel(x_sample[:, None], x_sample[None, :], period=2.0, length_scale=0.5)\n",
    "    samples = np.random.multivariate_normal(np.zeros(len(x_sample)), K + 1e-6*np.eye(len(x_sample)), n_samples)\n",
    "    for i in range(n_samples):\n",
    "        ax.plot(x_sample, samples[i], alpha=0.7, linewidth=1.5)\n",
    "    ax.set_title('Functions from Periodic Prior', fontweight='bold')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('f(x)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_kernels()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "1. RBF: Very smooth functions. Good for gradual trends.\n",
    "   - Larger length scale → slower correlation decay → smoother functions\n",
    "\n",
    "2. Matérn: More realistic than RBF. Finite differentiability.\n",
    "   - Lower ν → rougher functions → better for volatile prices\n",
    "\n",
    "3. Periodic: Repeating patterns. Perfect for seasonal commodities.\n",
    "   - Period matches the cycle (e.g., 12 months for nat gas)\n",
    "\n",
    "**Trading Application**: \n",
    "- Copper: Matérn (economic cycles are somewhat rough)\n",
    "- Natural Gas: Periodic (winter/summer demand)\n",
    "- Gold: RBF (smooth flight-to-safety trends)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GP Regression with PyMC\n",
    "\n",
    "### 3.1 The GP Regression Model\n",
    "\n",
    "**Generative model**:\n",
    "\n",
    "$$\\begin{align}\n",
    "f(x) &\\sim \\mathcal{GP}(0, k(x, x')) \\quad \\text{(latent function)} \\\\\n",
    "y_i &= f(x_i) + \\epsilon_i \\quad \\text{(observations)} \\\\\n",
    "\\epsilon_i &\\sim \\mathcal{N}(0, \\sigma^2) \\quad \\text{(noise)}\n",
    "\\end{align}$$\n",
    "\n",
    "**Posterior predictive** at new points $x_*$:\n",
    "\n",
    "$$p(f_* | x_*, X, y) = \\mathcal{N}(\\mu_*, \\Sigma_*)$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mu_* &= K(x_*, X)[K(X, X) + \\sigma^2 I]^{-1} y \\\\\n",
    "\\Sigma_* &= K(x_*, x_*) - K(x_*, X)[K(X, X) + \\sigma^2 I]^{-1} K(X, x_*)\n",
    "\\end{align}$$\n",
    "\n",
    "**Key insight**: Posterior mean is a weighted average of training data, with weights determined by kernel similarity.\n",
    "\n",
    "### 3.2 Implementing GP Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data: non-linear price trend\n",
    "def generate_nonlinear_price_data(n=100, noise=0.5):\n",
    "    \"\"\"\n",
    "    Generate synthetic commodity price data with non-linear trend.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    t = np.linspace(0, 4*np.pi, n)\n",
    "    \n",
    "    # True function: smooth non-linear trend\n",
    "    f_true = 100 + 10*np.sin(t) + 0.5*t**2 + 2*np.cos(2*t)\n",
    "    \n",
    "    # Observed prices (with noise)\n",
    "    y = f_true + np.random.normal(0, noise, n)\n",
    "    \n",
    "    return t, y, f_true\n",
    "\n",
    "# Generate data\n",
    "t_train, y_train, f_true = generate_nonlinear_price_data(n=80, noise=2.0)\n",
    "t_test = np.linspace(0, 4*np.pi, 200)\n",
    "\n",
    "# Fit GP model with PyMC\n",
    "with pm.Model() as gp_model:\n",
    "    # Hyperparameters (priors)\n",
    "    ℓ = pm.Gamma(\"ℓ\", alpha=2, beta=1)  # Length scale\n",
    "    η = pm.HalfNormal(\"η\", sigma=5.0)   # Amplitude\n",
    "    σ = pm.HalfNormal(\"σ\", sigma=2.0)   # Noise\n",
    "    \n",
    "    # Covariance function\n",
    "    cov_func = η**2 * pm.gp.cov.ExpQuad(1, ls=ℓ)\n",
    "    \n",
    "    # GP\n",
    "    gp = pm.gp.Marginal(cov_func=cov_func)\n",
    "    \n",
    "    # Likelihood\n",
    "    y_obs = gp.marginal_likelihood(\"y_obs\", X=t_train[:, None], y=y_train, sigma=σ)\n",
    "    \n",
    "    # Sample posterior\n",
    "    trace = pm.sample(1000, tune=1000, chains=2, random_seed=42, progressbar=True)\n",
    "\n",
    "# Posterior predictive\n",
    "with gp_model:\n",
    "    f_pred = gp.conditional(\"f_pred\", t_test[:, None])\n",
    "    pred_samples = pm.sample_posterior_predictive(trace, var_names=[\"f_pred\"], random_seed=42, progressbar=True)\n",
    "\n",
    "print(\"\\nGP model fitted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Extract predictions\n",
    "f_pred_mean = pred_samples.posterior_predictive['f_pred'].mean(dim=['chain', 'draw']).values\n",
    "f_pred_std = pred_samples.posterior_predictive['f_pred'].std(dim=['chain', 'draw']).values\n",
    "\n",
    "# Plot 1: GP fit with uncertainty\n",
    "ax = axes[0]\n",
    "ax.scatter(t_train, y_train, c='black', s=40, alpha=0.6, label='Observed prices', zorder=3)\n",
    "ax.plot(t_test, f_pred_mean, 'blue', linewidth=2, label='GP posterior mean', zorder=2)\n",
    "ax.fill_between(t_test, \n",
    "                f_pred_mean - 1.96*f_pred_std,\n",
    "                f_pred_mean + 1.96*f_pred_std,\n",
    "                alpha=0.3, color='blue', label='95% credible interval', zorder=1)\n",
    "ax.set_xlabel('Time', fontsize=12)\n",
    "ax.set_ylabel('Price ($)', fontsize=12)\n",
    "ax.set_title('Gaussian Process Regression: Non-Linear Price Trend', fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Hyperparameter posteriors\n",
    "ax = axes[1]\n",
    "params = ['ℓ', 'η', 'σ']\n",
    "param_names = ['Length Scale (ℓ)', 'Amplitude (η)', 'Noise (σ)']\n",
    "for i, (param, name) in enumerate(zip(params, param_names)):\n",
    "    samples = trace.posterior[param].values.flatten()\n",
    "    ax.hist(samples, bins=30, alpha=0.6, label=name, density=True)\n",
    "ax.set_xlabel('Parameter Value', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('Posterior Distributions of Hyperparameters', fontsize=13, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HYPERPARAMETER POSTERIORS\")\n",
    "print(\"=\"*70)\n",
    "for param, name in zip(params, param_names):\n",
    "    samples = trace.posterior[param].values.flatten()\n",
    "    print(f\"{name:20s}: {np.mean(samples):.3f} ± {np.std(samples):.3f}\")\n",
    "    print(f\"  95% CI: [{np.percentile(samples, 2.5):.3f}, {np.percentile(samples, 97.5):.3f}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\"\"\n",
    "Length Scale (ℓ): {np.mean(trace.posterior['ℓ'].values):.2f}\n",
    "  → Prices are correlated over ~{np.mean(trace.posterior['ℓ'].values):.2f} time units\n",
    "  → Shorter length scale = more flexible (fits local variations)\n",
    "  → Longer length scale = smoother (global trends)\n",
    "\n",
    "Amplitude (η): {np.mean(trace.posterior['η'].values):.2f}\n",
    "  → Typical deviation from mean is ${np.mean(trace.posterior['η'].values):.2f}\n",
    "  → Controls vertical scale of fluctuations\n",
    "\n",
    "Noise (σ): {np.mean(trace.posterior['σ'].values):.2f}\n",
    "  → Typical observation error is ${np.mean(trace.posterior['σ'].values):.2f}\n",
    "  → Higher noise → wider uncertainty bands\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Combining Kernels for Complex Patterns\n",
    "\n",
    "Real commodity prices exhibit **multiple patterns simultaneously**:\n",
    "- Long-term trends (economic growth)\n",
    "- Seasonal cycles (weather, demand patterns)\n",
    "- Short-term fluctuations (supply shocks)\n",
    "\n",
    "We can **compose kernels** to capture these patterns:\n",
    "\n",
    "### 4.1 Kernel Addition\n",
    "\n",
    "$$k_{\\text{sum}}(x, x') = k_1(x, x') + k_2(x, x')$$\n",
    "\n",
    "**Effect**: Model captures patterns from **both** kernels independently.\n",
    "\n",
    "**Example**: $k_{\\text{trend}} + k_{\\text{seasonal}}$ → trend plus seasonality\n",
    "\n",
    "### 4.2 Kernel Multiplication\n",
    "\n",
    "$$k_{\\text{product}}(x, x') = k_1(x, x') \\times k_2(x, x')$$\n",
    "\n",
    "**Effect**: Model captures patterns that are **modulated** by each other.\n",
    "\n",
    "**Example**: $k_{\\text{RBF}} \\times k_{\\text{periodic}}$ → locally periodic (changing amplitude)\n",
    "\n",
    "### 4.3 Practical Example: Natural Gas Prices\n",
    "\n",
    "Natural gas exhibits:\n",
    "1. **Long-term trend**: Growing demand over years\n",
    "2. **Seasonal pattern**: Winter heating, summer cooling\n",
    "3. **Noise**: Short-term supply/demand imbalances\n",
    "\n",
    "**Model**: \n",
    "$$k_{\\text{total}} = k_{\\text{RBF}}(\\text{trend}) + k_{\\text{Periodic}}(\\text{seasonal}) + k_{\\text{White Noise}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic natural gas price data\n",
    "def generate_gas_prices(n=200):\n",
    "    \"\"\"\n",
    "    Simulate natural gas prices with trend + seasonality.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    t = np.linspace(0, 4, n)  # 4 years, monthly\n",
    "    \n",
    "    # Components\n",
    "    trend = 3.0 + 0.5*t  # Growing demand\n",
    "    seasonal = 1.5*np.sin(2*np.pi*t)  # Annual cycle\n",
    "    noise = np.random.normal(0, 0.3, n)\n",
    "    \n",
    "    price = trend + seasonal + noise\n",
    "    \n",
    "    return t, price\n",
    "\n",
    "t_gas, price_gas = generate_gas_prices(n=150)\n",
    "t_pred_gas = np.linspace(0, 5, 300)  # Forecast 1 year ahead\n",
    "\n",
    "# Fit composite kernel GP\n",
    "with pm.Model() as composite_model:\n",
    "    # Trend component (RBF)\n",
    "    ℓ_trend = pm.Gamma(\"ℓ_trend\", alpha=2, beta=0.5)  # Long length scale for trend\n",
    "    η_trend = pm.HalfNormal(\"η_trend\", sigma=3.0)\n",
    "    cov_trend = η_trend**2 * pm.gp.cov.ExpQuad(1, ls=ℓ_trend)\n",
    "    \n",
    "    # Seasonal component (Periodic)\n",
    "    period = 1.0  # Annual (in years)\n",
    "    ℓ_seasonal = pm.Gamma(\"ℓ_seasonal\", alpha=2, beta=2)\n",
    "    η_seasonal = pm.HalfNormal(\"η_seasonal\", sigma=2.0)\n",
    "    cov_seasonal = η_seasonal**2 * pm.gp.cov.Periodic(1, period=period, ls=ℓ_seasonal)\n",
    "    \n",
    "    # Combine kernels (additive)\n",
    "    cov_total = cov_trend + cov_seasonal\n",
    "    \n",
    "    # Noise\n",
    "    σ = pm.HalfNormal(\"σ\", sigma=0.5)\n",
    "    \n",
    "    # GP\n",
    "    gp = pm.gp.Marginal(cov_func=cov_total)\n",
    "    \n",
    "    # Likelihood\n",
    "    y_obs = gp.marginal_likelihood(\"y_obs\", X=t_gas[:, None], y=price_gas, sigma=σ)\n",
    "    \n",
    "    # Sample\n",
    "    trace_comp = pm.sample(1000, tune=1000, chains=2, random_seed=42, progressbar=True)\n",
    "\n",
    "# Predictions\n",
    "with composite_model:\n",
    "    f_pred_gas = gp.conditional(\"f_pred_gas\", t_pred_gas[:, None])\n",
    "    pred_samples_gas = pm.sample_posterior_predictive(trace_comp, var_names=[\"f_pred_gas\"], \n",
    "                                                       random_seed=42, progressbar=True)\n",
    "\n",
    "print(\"\\nComposite kernel GP fitted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize composite kernel results\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Extract predictions\n",
    "f_mean_gas = pred_samples_gas.posterior_predictive['f_pred_gas'].mean(dim=['chain', 'draw']).values\n",
    "f_std_gas = pred_samples_gas.posterior_predictive['f_pred_gas'].std(dim=['chain', 'draw']).values\n",
    "\n",
    "# Plot 1: Full model forecast\n",
    "ax = axes[0]\n",
    "ax.scatter(t_gas, price_gas, c='black', s=30, alpha=0.5, label='Observed prices', zorder=3)\n",
    "ax.plot(t_pred_gas, f_mean_gas, 'blue', linewidth=2.5, label='GP forecast', zorder=2)\n",
    "ax.fill_between(t_pred_gas,\n",
    "                f_mean_gas - 1.96*f_std_gas,\n",
    "                f_mean_gas + 1.96*f_std_gas,\n",
    "                alpha=0.25, color='blue', label='95% CI', zorder=1)\n",
    "ax.axvline(t_gas[-1], color='red', linestyle='--', linewidth=2, label='Forecast start', alpha=0.5)\n",
    "ax.set_xlabel('Time (years)', fontsize=12)\n",
    "ax.set_ylabel('Price ($/MMBtu)', fontsize=12)\n",
    "ax.set_title('Natural Gas: Composite Kernel (Trend + Seasonality)', fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Decomposition (approximate)\n",
    "# Extract trend and seasonal components separately\n",
    "ax = axes[1]\n",
    "\n",
    "# For visualization, we'll refit with individual components\n",
    "# Trend only\n",
    "with pm.Model() as trend_only:\n",
    "    ℓ_t = pm.Gamma(\"ℓ_t\", alpha=2, beta=0.5)\n",
    "    η_t = pm.HalfNormal(\"η_t\", sigma=3.0)\n",
    "    cov_t = η_t**2 * pm.gp.cov.ExpQuad(1, ls=ℓ_t)\n",
    "    σ_t = pm.HalfNormal(\"σ_t\", sigma=1.0)\n",
    "    gp_t = pm.gp.Marginal(cov_func=cov_t)\n",
    "    y_t = gp_t.marginal_likelihood(\"y_t\", X=t_gas[:, None], y=price_gas, sigma=σ_t)\n",
    "    trace_t = pm.sample(500, tune=500, chains=1, random_seed=42, progressbar=False)\n",
    "    f_trend = gp_t.conditional(\"f_trend\", t_pred_gas[:, None])\n",
    "    pred_t = pm.sample_posterior_predictive(trace_t, var_names=[\"f_trend\"], random_seed=42, progressbar=False)\n",
    "\n",
    "f_trend_mean = pred_t.posterior_predictive['f_trend'].mean(dim=['chain', 'draw']).values\n",
    "\n",
    "# Plot components\n",
    "ax.plot(t_pred_gas, f_mean_gas, 'purple', linewidth=2.5, label='Full model', alpha=0.8)\n",
    "ax.plot(t_pred_gas, f_trend_mean, 'green', linewidth=2, label='Trend component (approx)', linestyle='--')\n",
    "ax.plot(t_pred_gas, f_mean_gas - f_trend_mean + np.mean(price_gas), 'orange', \n",
    "        linewidth=2, label='Seasonal component (approx)', linestyle='-.')\n",
    "ax.axvline(t_gas[-1], color='red', linestyle='--', linewidth=2, alpha=0.5)\n",
    "ax.set_xlabel('Time (years)', fontsize=12)\n",
    "ax.set_ylabel('Price ($/MMBtu)', fontsize=12)\n",
    "ax.set_title('Decomposition: Trend + Seasonality', fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPOSITE KERNEL INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "1. Trend Component (RBF):\n",
    "   - Captures long-term growth in demand\n",
    "   - Smooth evolution over years\n",
    "\n",
    "2. Seasonal Component (Periodic):\n",
    "   - Annual cycle (winter peaks, summer lows)\n",
    "   - Repeating pattern with consistent period\n",
    "\n",
    "3. Combined Model:\n",
    "   - Forecasts BOTH trend and seasonality\n",
    "   - Uncertainty grows in forecast period (as expected)\n",
    "   - Can detect when seasonality amplitude changes\n",
    "\n",
    "**Trading Application**:\n",
    "- Buy in summer (seasonal low), sell in winter (seasonal high)\n",
    "- Adjust positions based on trend direction\n",
    "- Size trades using uncertainty bands (wider bands = smaller positions)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Optimization and Interpretation\n",
    "\n",
    "### 5.1 The Role of Hyperparameters\n",
    "\n",
    "GP hyperparameters control the **prior** over functions. They determine:\n",
    "\n",
    "1. **Length scale ($\\ell$)**: How far we extrapolate correlations\n",
    "   - Small $\\ell$ → wiggly functions (overfitting risk)\n",
    "   - Large $\\ell$ → smooth functions (underfitting risk)\n",
    "\n",
    "2. **Amplitude ($\\eta$)**: Vertical scale of variation\n",
    "   - Controls prior variance of function values\n",
    "\n",
    "3. **Noise ($\\sigma$)**: Observation error\n",
    "   - High $\\sigma$ → less trust in individual observations\n",
    "   - Low $\\sigma$ → interpolate through points\n",
    "\n",
    "### 5.2 Learning Hyperparameters\n",
    "\n",
    "Two approaches:\n",
    "\n",
    "**Maximum Likelihood (Type-II ML)**:\n",
    "- Maximize marginal likelihood $p(y|X, \\theta)$ w.r.t. hyperparameters $\\theta$\n",
    "- Fast but gives point estimates (no uncertainty)\n",
    "\n",
    "**Full Bayes**:\n",
    "- Place priors on hyperparameters\n",
    "- Sample posterior $p(\\theta | X, y)$ using MCMC\n",
    "- Slower but accounts for hyperparameter uncertainty\n",
    "\n",
    "PyMC uses **full Bayes** by default, giving us uncertainty about hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze hyperparameter posteriors from composite model\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 9))\n",
    "\n",
    "params = ['ℓ_trend', 'η_trend', 'ℓ_seasonal', 'η_seasonal', 'σ']\n",
    "param_names = ['Trend Length Scale', 'Trend Amplitude', 'Seasonal Length Scale', \n",
    "               'Seasonal Amplitude', 'Noise']\n",
    "\n",
    "for i, (param, name) in enumerate(zip(params, param_names)):\n",
    "    ax = axes.flatten()[i]\n",
    "    \n",
    "    samples = trace_comp.posterior[param].values.flatten()\n",
    "    \n",
    "    # Histogram\n",
    "    ax.hist(samples, bins=30, alpha=0.7, density=True, color='steelblue', edgecolor='black')\n",
    "    \n",
    "    # Add mean line\n",
    "    mean_val = np.mean(samples)\n",
    "    ax.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean = {mean_val:.2f}')\n",
    "    \n",
    "    # 95% CI\n",
    "    ci_low, ci_high = np.percentile(samples, [2.5, 97.5])\n",
    "    ax.axvline(ci_low, color='orange', linestyle=':', linewidth=1.5)\n",
    "    ax.axvline(ci_high, color='orange', linestyle=':', linewidth=1.5, label=f'95% CI')\n",
    "    \n",
    "    ax.set_xlabel('Value', fontsize=11)\n",
    "    ax.set_ylabel('Density', fontsize=11)\n",
    "    ax.set_title(name, fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide extra subplot\n",
    "axes.flatten()[5].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HYPERPARAMETER POSTERIOR SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Parameter':<25} {'Mean':>10} {'Std':>10} {'95% CI':>20}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for param, name in zip(params, param_names):\n",
    "    samples = trace_comp.posterior[param].values.flatten()\n",
    "    mean_val = np.mean(samples)\n",
    "    std_val = np.std(samples)\n",
    "    ci = np.percentile(samples, [2.5, 97.5])\n",
    "    print(f\"{name:<25} {mean_val:>10.3f} {std_val:>10.3f} [{ci[0]:>6.3f}, {ci[1]:>6.3f}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ECONOMIC INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "ℓ_trend_mean = np.mean(trace_comp.posterior['ℓ_trend'].values)\n",
    "ℓ_seasonal_mean = np.mean(trace_comp.posterior['ℓ_seasonal'].values)\n",
    "η_trend_mean = np.mean(trace_comp.posterior['η_trend'].values)\n",
    "η_seasonal_mean = np.mean(trace_comp.posterior['η_seasonal'].values)\n",
    "\n",
    "print(f\"\"\"\n",
    "Trend Length Scale: {ℓ_trend_mean:.2f} years\n",
    "  → Trend changes smoothly over ~{ℓ_trend_mean:.2f} years\n",
    "  → Long length scale = persistent directional moves\n",
    "\n",
    "Seasonal Length Scale: {ℓ_seasonal_mean:.2f}\n",
    "  → Controls smoothness WITHIN each season\n",
    "  → Higher value = smoother seasonal curves\n",
    "\n",
    "Amplitude Ratio (Trend/Seasonal): {η_trend_mean/η_seasonal_mean:.2f}\n",
    "  → Trend is {η_trend_mean/η_seasonal_mean:.2f}x more important than seasonality\n",
    "  → Useful for position sizing (trend vs mean-reversion strategies)\n",
    "\n",
    "**Trading Insight**:\n",
    "If trend amplitude >> seasonal amplitude:\n",
    "  → Focus on trend-following strategies\n",
    "  → Use seasonality for entry/exit timing\n",
    "\n",
    "If seasonal amplitude >> trend amplitude:\n",
    "  → Focus on seasonal trading (buy summer, sell winter)\n",
    "  → Trend is less reliable for directional bets\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sparse Gaussian Processes for Large Datasets\n",
    "\n",
    "### 6.1 The Computational Challenge\n",
    "\n",
    "Standard GP regression requires:\n",
    "- **Covariance matrix**: $K \\in \\mathbb{R}^{n \\times n}$\n",
    "- **Matrix inversion**: $O(n^3)$ complexity\n",
    "- **Memory**: $O(n^2)$ storage\n",
    "\n",
    "For $n > 1000$ observations, this becomes prohibitive.\n",
    "\n",
    "### 6.2 Sparse Approximations\n",
    "\n",
    "**Idea**: Use $m \\ll n$ **inducing points** to approximate the full GP.\n",
    "\n",
    "**Inducing points** $\\mathbf{u}$ are a set of latent function values at locations $Z$ that summarize the full GP.\n",
    "\n",
    "**Complexity reduction**:\n",
    "- Standard GP: $O(n^3)$\n",
    "- Sparse GP: $O(nm^2)$ where $m \\ll n$\n",
    "\n",
    "**Popular methods**:\n",
    "1. **FITC** (Fully Independent Training Conditional)\n",
    "2. **SVGP** (Stochastic Variational GP)\n",
    "3. **VFE** (Variational Free Energy)\n",
    "\n",
    "PyMC supports sparse GPs through `pm.gp.Marginal` with inducing points.\n",
    "\n",
    "### 6.3 Practical Example: High-Frequency Commodity Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate large dataset (daily data for several years)\n",
    "def generate_large_copper_data(n=2000):\n",
    "    \"\"\"\n",
    "    Simulate daily copper prices with trend and cycles.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    t = np.linspace(0, 10, n)  # 10 years daily\n",
    "    \n",
    "    # Components\n",
    "    trend = 6000 + 200*t + 50*np.sin(0.5*t)  # Long-term trend\n",
    "    cycle = 500*np.sin(2*np.pi*t/2.5)  # Multi-year cycle\n",
    "    noise = np.random.normal(0, 100, n)\n",
    "    \n",
    "    price = trend + cycle + noise\n",
    "    \n",
    "    return t, price\n",
    "\n",
    "# Generate data\n",
    "t_copper, price_copper = generate_large_copper_data(n=1500)\n",
    "\n",
    "print(f\"Dataset size: {len(t_copper)} observations\")\n",
    "print(f\"Standard GP would require: {len(t_copper)**2 * 8 / 1e9:.2f} GB for covariance matrix\")\n",
    "print(f\"Complexity: O(n³) = O({len(t_copper)**3 / 1e9:.2f} billion operations)\")\n",
    "print(\"\\nUsing sparse approximation with m=50 inducing points...\\n\")\n",
    "\n",
    "# Sparse GP with inducing points\n",
    "m = 50  # Number of inducing points\n",
    "Z = np.linspace(t_copper.min(), t_copper.max(), m)[:, None]  # Inducing point locations\n",
    "\n",
    "with pm.Model() as sparse_gp:\n",
    "    # Hyperparameters\n",
    "    ℓ = pm.Gamma(\"ℓ\", alpha=2, beta=0.5)\n",
    "    η = pm.HalfNormal(\"η\", sigma=500)\n",
    "    σ = pm.HalfNormal(\"σ\", sigma=150)\n",
    "    \n",
    "    # Covariance function\n",
    "    cov = η**2 * pm.gp.cov.Matern52(1, ls=ℓ)\n",
    "    \n",
    "    # Sparse GP (using inducing points approximation)\n",
    "    gp_sparse = pm.gp.MarginalSparse(cov_func=cov, approx=\"FITC\")\n",
    "    \n",
    "    # Likelihood with inducing points\n",
    "    y_obs = gp_sparse.marginal_likelihood(\n",
    "        \"y_obs\", \n",
    "        X=t_copper[:, None], \n",
    "        Xu=Z,  # Inducing points\n",
    "        y=price_copper, \n",
    "        sigma=σ\n",
    "    )\n",
    "    \n",
    "    # Sample (much faster than full GP!)\n",
    "    trace_sparse = pm.sample(500, tune=500, chains=2, random_seed=42, progressbar=True)\n",
    "\n",
    "print(\"\\nSparse GP fitted successfully!\")\n",
    "print(f\"Complexity reduction: {len(t_copper)**3 / (len(t_copper) * m**2):.0f}x faster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions with sparse GP\n",
    "t_pred_copper = np.linspace(0, 11, 500)\n",
    "\n",
    "with sparse_gp:\n",
    "    f_pred_copper = gp_sparse.conditional(\"f_pred_copper\", t_pred_copper[:, None], pred_noise=True)\n",
    "    pred_copper = pm.sample_posterior_predictive(trace_sparse, var_names=[\"f_pred_copper\"], \n",
    "                                                  random_seed=42, progressbar=True)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "f_mean_copper = pred_copper.posterior_predictive['f_pred_copper'].mean(dim=['chain', 'draw']).values\n",
    "f_std_copper = pred_copper.posterior_predictive['f_pred_copper'].std(dim=['chain', 'draw']).values\n",
    "\n",
    "# Plot 1: Full view\n",
    "ax = axes[0]\n",
    "ax.scatter(t_copper[::10], price_copper[::10], c='black', s=15, alpha=0.3, label='Observed (subsampled)')\n",
    "ax.scatter(Z.flatten(), price_copper[np.searchsorted(t_copper, Z.flatten())], \n",
    "           c='red', s=80, marker='x', linewidths=2, label=f'{m} Inducing points', zorder=5)\n",
    "ax.plot(t_pred_copper, f_mean_copper, 'blue', linewidth=2, label='Sparse GP', zorder=3)\n",
    "ax.fill_between(t_pred_copper,\n",
    "                f_mean_copper - 1.96*f_std_copper,\n",
    "                f_mean_copper + 1.96*f_std_copper,\n",
    "                alpha=0.2, color='blue', label='95% CI')\n",
    "ax.axvline(t_copper[-1], color='green', linestyle='--', linewidth=2, label='Forecast start', alpha=0.6)\n",
    "ax.set_xlabel('Time (years)', fontsize=12)\n",
    "ax.set_ylabel('Price ($/ton)', fontsize=12)\n",
    "ax.set_title(f'Sparse GP: Copper Prices ({len(t_copper)} observations, {m} inducing points)', \n",
    "             fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Zoom on forecast region\n",
    "ax = axes[1]\n",
    "forecast_mask = t_copper > 8\n",
    "pred_mask = t_pred_copper > 8\n",
    "\n",
    "ax.scatter(t_copper[forecast_mask], price_copper[forecast_mask], c='black', s=30, alpha=0.5, \n",
    "           label='Recent observations')\n",
    "ax.plot(t_pred_copper[pred_mask], f_mean_copper[pred_mask], 'blue', linewidth=2.5, label='Forecast')\n",
    "ax.fill_between(t_pred_copper[pred_mask],\n",
    "                f_mean_copper[pred_mask] - 1.96*f_std_copper[pred_mask],\n",
    "                f_mean_copper[pred_mask] + 1.96*f_std_copper[pred_mask],\n",
    "                alpha=0.3, color='blue', label='95% CI')\n",
    "ax.axvline(t_copper[-1], color='green', linestyle='--', linewidth=2, label='Forecast start')\n",
    "ax.set_xlabel('Time (years)', fontsize=12)\n",
    "ax.set_ylabel('Price ($/ton)', fontsize=12)\n",
    "ax.set_title('Forecast Region (Last 2 years + 1 year ahead)', fontsize=13, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SPARSE GP ADVANTAGES\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\"\"\n",
    "1. **Computational Efficiency**:\n",
    "   - Full GP: O(n³) = O({len(t_copper)**3/1e9:.1f}B) operations\n",
    "   - Sparse GP: O(nm²) = O({len(t_copper)*m**2/1e6:.1f}M) operations\n",
    "   - Speedup: ~{len(t_copper)**2 / m**2:.0f}x\n",
    "\n",
    "2. **Memory Savings**:\n",
    "   - Full GP: {len(t_copper)**2 * 8 / 1e9:.2f} GB\n",
    "   - Sparse GP: {len(t_copper) * m * 8 / 1e6:.2f} MB\n",
    "   - Reduction: ~{len(t_copper) / m:.0f}x\n",
    "\n",
    "3. **Accuracy**:\n",
    "   - With {m} well-placed inducing points, captures main patterns\n",
    "   - Minor loss in fit quality vs full GP\n",
    "   - Inducing point placement matters!\n",
    "\n",
    "**When to Use Sparse GPs**:\n",
    "- Daily/hourly commodity price data (n > 1000)\n",
    "- Real-time trading systems (need fast inference)\n",
    "- Limited computational resources\n",
    "\n",
    "**Inducing Point Selection**:\n",
    "- Uniform spacing (simple, works well)\n",
    "- K-means clustering of inputs (adaptive)\n",
    "- Learn locations (more complex, marginal benefit)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Practical Example: Copper Price Forecasting with Regime Detection\n",
    "\n",
    "Let's apply everything we've learned to a realistic copper trading scenario:\n",
    "\n",
    "**Challenge**: Copper prices exhibit:\n",
    "1. Long-term trends (economic cycles)\n",
    "2. Regime changes (China demand shocks, supply disruptions)\n",
    "3. Non-linear patterns\n",
    "\n",
    "**Solution**: Use GP with Matérn kernel to capture regime changes and forecast with uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic copper price data with regime change\n",
    "def generate_copper_with_regimes(n=300):\n",
    "    \"\"\"\n",
    "    Simulate copper prices with a regime change (China boom).\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    t = np.linspace(0, 10, n)\n",
    "    \n",
    "    # Regime 1 (years 0-5): Moderate growth\n",
    "    regime1 = 6000 + 100*t[:n//2] + np.random.normal(0, 200, n//2)\n",
    "    \n",
    "    # Regime 2 (years 5-10): China boom - sharp rise then volatility\n",
    "    t2 = t[n//2:]\n",
    "    regime2 = 6500 + 800*np.tanh((t2 - 5)*0.8) + 300*np.sin(2*t2) + np.random.normal(0, 300, n - n//2)\n",
    "    \n",
    "    price = np.concatenate([regime1, regime2])\n",
    "    \n",
    "    return t, price\n",
    "\n",
    "# Generate data\n",
    "t_cu, price_cu = generate_copper_with_regimes(n=250)\n",
    "\n",
    "# Split: Train on first 80%, forecast last 20%\n",
    "split_idx = int(0.8 * len(t_cu))\n",
    "t_train_cu = t_cu[:split_idx]\n",
    "price_train_cu = price_cu[:split_idx]\n",
    "t_test_cu = t_cu[split_idx:]\n",
    "price_test_cu = price_cu[split_idx:]\n",
    "\n",
    "# Fit GP with Matérn kernel (captures regime changes better than RBF)\n",
    "with pm.Model() as copper_model:\n",
    "    # Hyperparameters\n",
    "    ℓ = pm.Gamma(\"ℓ\", alpha=2, beta=1)\n",
    "    η = pm.HalfNormal(\"η\", sigma=800)\n",
    "    σ = pm.HalfNormal(\"σ\", sigma=300)\n",
    "    \n",
    "    # Matérn 3/2 kernel (less smooth than RBF, captures regime changes)\n",
    "    cov = η**2 * pm.gp.cov.Matern32(1, ls=ℓ)\n",
    "    \n",
    "    # GP\n",
    "    gp_cu = pm.gp.Marginal(cov_func=cov)\n",
    "    \n",
    "    # Likelihood\n",
    "    y_obs = gp_cu.marginal_likelihood(\"y_obs\", X=t_train_cu[:, None], y=price_train_cu, sigma=σ)\n",
    "    \n",
    "    # Sample\n",
    "    trace_cu = pm.sample(1000, tune=1000, chains=2, random_seed=42, progressbar=True)\n",
    "\n",
    "# Forecast\n",
    "t_forecast_cu = np.linspace(t_cu.min(), t_cu.max() + 1, 400)\n",
    "\n",
    "with copper_model:\n",
    "    f_forecast_cu = gp_cu.conditional(\"f_forecast_cu\", t_forecast_cu[:, None])\n",
    "    pred_cu_final = pm.sample_posterior_predictive(trace_cu, var_names=[\"f_forecast_cu\"], \n",
    "                                                    random_seed=42, progressbar=True)\n",
    "\n",
    "print(\"\\nCopper forecasting model fitted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize final copper forecast\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "f_mean_cu = pred_cu_final.posterior_predictive['f_forecast_cu'].mean(dim=['chain', 'draw']).values\n",
    "f_std_cu = pred_cu_final.posterior_predictive['f_forecast_cu'].std(dim=['chain', 'draw']).values\n",
    "\n",
    "# Plot 1: Full history + forecast\n",
    "ax = axes[0]\n",
    "ax.scatter(t_train_cu, price_train_cu, c='black', s=40, alpha=0.6, label='Training data', zorder=3)\n",
    "ax.scatter(t_test_cu, price_test_cu, c='red', s=40, alpha=0.8, label='Held-out test data', zorder=3)\n",
    "ax.plot(t_forecast_cu, f_mean_cu, 'blue', linewidth=2.5, label='GP forecast', zorder=2)\n",
    "ax.fill_between(t_forecast_cu,\n",
    "                f_mean_cu - 1.96*f_std_cu,\n",
    "                f_mean_cu + 1.96*f_std_cu,\n",
    "                alpha=0.25, color='blue', label='95% CI', zorder=1)\n",
    "ax.axvline(t_train_cu[-1], color='green', linestyle='--', linewidth=2, \n",
    "           label='Train/test split', alpha=0.6)\n",
    "ax.axvline(5, color='orange', linestyle=':', linewidth=2, \n",
    "           label='Regime change (China boom)', alpha=0.6)\n",
    "ax.set_xlabel('Time (years)', fontsize=12)\n",
    "ax.set_ylabel('Price ($/ton)', fontsize=12)\n",
    "ax.set_title('Copper Price Forecast: GP with Matérn Kernel', fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='upper left', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Prediction intervals and uncertainty growth\n",
    "ax = axes[1]\n",
    "ax.plot(t_forecast_cu, f_std_cu, 'purple', linewidth=2.5, label='Uncertainty (std dev)')\n",
    "ax.axvline(t_train_cu[-1], color='green', linestyle='--', linewidth=2, \n",
    "           label='Train/test split', alpha=0.6)\n",
    "ax.fill_between(t_forecast_cu, 0, f_std_cu, alpha=0.3, color='purple')\n",
    "ax.set_xlabel('Time (years)', fontsize=12)\n",
    "ax.set_ylabel('Predictive Uncertainty ($/ton)', fontsize=12)\n",
    "ax.set_title('Forecast Uncertainty Growth', fontsize=13, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate forecast accuracy on test set\n",
    "test_mask = (t_forecast_cu >= t_test_cu[0]) & (t_forecast_cu <= t_test_cu[-1])\n",
    "f_test_mean = f_mean_cu[test_mask]\n",
    "f_test_std = f_std_cu[test_mask]\n",
    "\n",
    "# Interpolate predictions to match test times\n",
    "from scipy.interpolate import interp1d\n",
    "interp_mean = interp1d(t_forecast_cu, f_mean_cu, kind='linear')\n",
    "interp_std = interp1d(t_forecast_cu, f_std_cu, kind='linear')\n",
    "\n",
    "pred_test_mean = interp_mean(t_test_cu)\n",
    "pred_test_std = interp_std(t_test_cu)\n",
    "\n",
    "mae = np.mean(np.abs(price_test_cu - pred_test_mean))\n",
    "rmse = np.sqrt(np.mean((price_test_cu - pred_test_mean)**2))\n",
    "coverage = np.mean((price_test_cu >= pred_test_mean - 1.96*pred_test_std) & \n",
    "                   (price_test_cu <= pred_test_mean + 1.96*pred_test_std))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FORECAST EVALUATION ON HELD-OUT TEST SET\")\n",
    "print(\"=\"*70)\n",
    "print(f\"MAE:  ${mae:.2f}/ton\")\n",
    "print(f\"RMSE: ${rmse:.2f}/ton\")\n",
    "print(f\"95% Interval Coverage: {coverage:.1%} (should be ~95% for calibrated forecasts)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRADING INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\"\"\n",
    "1. **Regime Detection**:\n",
    "   - GP automatically adapts to regime change at year 5\n",
    "   - Matérn kernel allows for \"kinks\" that RBF would smooth over\n",
    "\n",
    "2. **Uncertainty Quantification**:\n",
    "   - Uncertainty grows as we forecast further (as it should!)\n",
    "   - Narrower bands in stable periods, wider in volatile periods\n",
    "   - Use for position sizing: wide bands → reduce position\n",
    "\n",
    "3. **Forecast Calibration**:\n",
    "   - {coverage:.1%} of actual prices fall in 95% interval\n",
    "   - Well-calibrated forecasts enable proper risk management\n",
    "\n",
    "4. **Trading Strategies**:\n",
    "   - **Trend following**: When forecast slope is positive, go long\n",
    "   - **Mean reversion**: When price exits upper band, consider shorting\n",
    "   - **Volatility trading**: Wider bands → higher implied vol → option strategies\n",
    "\n",
    "5. **Risk Management**:\n",
    "   - VaR from predictive distribution: 5th percentile of forecast\n",
    "   - Position sizing: Inverse to forecast uncertainty\n",
    "   - Stop-losses: Place outside 95% CI to avoid noise-triggered exits\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary: When to Use Gaussian Processes\n",
    "\n",
    "### 8.1 GP Strengths\n",
    "\n",
    "| Strength | Why It Matters for Trading |\n",
    "|----------|---------------------------|\n",
    "| **Non-parametric** | Don't need to assume functional form (linear, quadratic, etc.) |\n",
    "| **Full distributions** | Get predictive uncertainty for every forecast |\n",
    "| **Kernel flexibility** | Encode domain knowledge (smoothness, periodicity) |\n",
    "| **Composability** | Combine trend + seasonality + noise naturally |\n",
    "| **Bayesian** | Hyperparameter uncertainty propagates to forecasts |\n",
    "| **Interpolation** | Excellent at filling gaps in historical data |\n",
    "\n",
    "### 8.2 GP Limitations\n",
    "\n",
    "| Limitation | Workaround |\n",
    "|------------|------------|\n",
    "| **Computational cost** | Use sparse approximations (FITC, SVGP) |\n",
    "| **Stationary kernels** | Most kernels assume stationary processes (can use non-stationary kernels) |\n",
    "| **High dimensions** | GPs struggle with many input features (use ARD or feature selection) |\n",
    "| **Extrapolation** | Uncertainty grows quickly beyond data (by design!) |\n",
    "\n",
    "### 8.3 Decision Guide: GP vs Other Methods\n",
    "\n",
    "**Use GP when**:\n",
    "- ✅ Small to medium datasets (n < 10,000)\n",
    "- ✅ Non-linear patterns expected\n",
    "- ✅ Uncertainty quantification critical\n",
    "- ✅ Prior knowledge about smoothness/seasonality\n",
    "- ✅ Interpolation important (missing data)\n",
    "\n",
    "**Consider alternatives when**:\n",
    "- ❌ Very large datasets (n > 100,000) → Neural networks, ensemble methods\n",
    "- ❌ Many input features (p > 50) → Random forests, boosting\n",
    "- ❌ Only point predictions needed → Linear models, ARIMA\n",
    "- ❌ Real-time constraints → Faster methods (local models)\n",
    "\n",
    "### 8.4 Key Takeaways\n",
    "\n",
    "1. **Kernels encode assumptions**: Choose kernels that match your beliefs about price dynamics\n",
    "\n",
    "2. **Combine kernels**: Real commodities have multiple patterns (trend + seasonality + noise)\n",
    "\n",
    "3. **Hyperparameters matter**: Length scales, amplitudes have economic interpretations\n",
    "\n",
    "4. **Sparse GPs scale**: Use inducing points for large datasets\n",
    "\n",
    "5. **Uncertainty is valuable**: GP predictive distributions enable sophisticated risk management\n",
    "\n",
    "6. **Matérn > RBF for trading**: Finite differentiability better matches real price dynamics\n",
    "\n",
    "7. **Regime changes**: GPs adapt automatically if length scale is not too large\n",
    "\n",
    "**Next steps**: In Module 9, we'll learn how to model **time-varying volatility** using stochastic volatility models and GARCH, building on the uncertainty quantification skills from GPs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Knowledge Check Quiz\n",
    "\n",
    "Test your understanding. Answers in the next cell.\n",
    "\n",
    "**Q1**: What does the length scale parameter $\\ell$ in a GP kernel control?\n",
    "- A) The vertical scale of the function\n",
    "- B) How far apart points can be and still be correlated\n",
    "- C) The noise level in observations\n",
    "- D) The period of oscillations\n",
    "\n",
    "**Q2**: For modeling seasonal commodity prices (e.g., natural gas), which kernel is most appropriate?\n",
    "- A) RBF only\n",
    "- B) White noise only\n",
    "- C) RBF + Periodic\n",
    "- D) Linear kernel\n",
    "\n",
    "**Q3**: Sparse GPs with $m$ inducing points reduce complexity from $O(n^3)$ to:\n",
    "- A) $O(n^2)$\n",
    "- B) $O(nm^2)$\n",
    "- C) $O(m^3)$\n",
    "- D) $O(n + m)$\n",
    "\n",
    "**Q4**: Why is the Matérn kernel often better than RBF for commodity prices?\n",
    "- A) It's faster to compute\n",
    "- B) It allows for regime changes and finite differentiability\n",
    "- C) It requires fewer hyperparameters\n",
    "- D) It always gives narrower uncertainty bands\n",
    "\n",
    "**Q5**: If a GP forecast shows very wide uncertainty bands in the future, you should:\n",
    "- A) Increase position size (more opportunity)\n",
    "- B) Reduce position size (more risk)\n",
    "- C) Ignore the forecast\n",
    "- D) Trade only at the mean prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz Answers\n",
    "print(\"=\"*70)\n",
    "print(\"QUIZ ANSWERS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Q1: B) How far apart points can be and still be correlated\n",
    "    The length scale ℓ controls the \"reach\" of correlation. Larger ℓ means\n",
    "    points further apart are still correlated (smoother functions).\n",
    "\n",
    "Q2: C) RBF + Periodic\n",
    "    RBF captures the trend, Periodic captures the annual cycle. Combining\n",
    "    them via kernel addition gives trend + seasonality.\n",
    "\n",
    "Q3: B) O(nm²)\n",
    "    Sparse GPs reduce complexity from O(n³) to O(nm²) where m << n is the\n",
    "    number of inducing points. This enables scaling to thousands of observations.\n",
    "\n",
    "Q4: B) It allows for regime changes and finite differentiability\n",
    "    RBF is infinitely differentiable (unrealistically smooth). Matérn with\n",
    "    ν=1.5 or 2.5 is only finitely differentiable, matching real price dynamics\n",
    "    with occasional kinks and regime changes.\n",
    "\n",
    "Q5: B) Reduce position size (more risk)\n",
    "    Wide uncertainty bands mean high forecast uncertainty. This translates\n",
    "    to higher risk. Bayesian risk management says: uncertainty → smaller positions.\n",
    "    Use Kelly criterion or volatility-adjusted sizing.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "Complete these in `exercises.ipynb`:\n",
    "\n",
    "### Exercise 1: Kernel Exploration (Easy)\n",
    "Generate synthetic data with known structure (linear trend + sine wave + noise). Fit GPs with:\n",
    "- RBF kernel only\n",
    "- Periodic kernel only\n",
    "- RBF + Periodic\n",
    "\n",
    "Compare forecast accuracy. Which kernel composition works best?\n",
    "\n",
    "### Exercise 2: Hyperparameter Sensitivity (Medium)\n",
    "Using the copper price data:\n",
    "1. Fit GPs with different prior choices for length scale\n",
    "2. Plot how posterior predictions change\n",
    "3. Calculate forecast coverage on test set\n",
    "4. What happens with too-small vs too-large length scale priors?\n",
    "\n",
    "### Exercise 3: Trading Strategy with GPs (Hard)\n",
    "Implement a GP-based trading strategy:\n",
    "1. Generate synthetic commodity prices with trend + noise\n",
    "2. Use rolling window GP forecasts\n",
    "3. Trade signals: \n",
    "   - Go long if forecast mean > current price + 1σ\n",
    "   - Go short if forecast mean < current price - 1σ\n",
    "4. Position sizing: Inverse to forecast uncertainty\n",
    "5. Backtest and calculate Sharpe ratio\n",
    "\n",
    "Compare to:\n",
    "- Buy-and-hold\n",
    "- Simple moving average crossover\n",
    "\n",
    "### Exercise 4: Multi-Output GP (Advanced)\n",
    "Build a multi-output GP for **pairs trading**:\n",
    "- Model two correlated commodities (e.g., WTI crude + Brent crude)\n",
    "- Use cross-covariance between outputs\n",
    "- Trade the spread when it deviates from GP forecast\n",
    "\n",
    "---\n",
    "\n",
    "## Next Module Preview\n",
    "\n",
    "In **Module 9: Volatility Modeling and Uncertainty Quantification**, we'll learn:\n",
    "- Time-varying volatility (GARCH, stochastic volatility)\n",
    "- Epistemic vs aleatoric uncertainty\n",
    "- VaR and CVaR from Bayesian posteriors\n",
    "- Volatility forecasting for risk management\n",
    "- Practical example: Crude oil volatility regime detection\n",
    "\n",
    "---\n",
    "\n",
    "*Module 8 Complete*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
